## 绪论（上）

计算模型=计算机=信息处理工具    
所谓算法,即特定计算模型下,旨在解决特定问题的指令序列:   
输入 待处理的信息(问题)   
输出 经处理的信息(答案)   
正确性 的确可以解决指定的问题   
确定性 任一算法都可以描述为一个由基本操作组成的序列   
可行性 每一基本操作都可实现,且在常数时间内完成   
有穷性 对于任何输入，经有穷次基本操作,都可以得到输出   

有穷性的反例算法:Hailstore,≤ 1结束，> 1 偶数时 ÷ 奇数时 ×3+1。这个逻辑的程序暂时还没有办法证明是否所有输入都有穷，虽然还没有反例 42、7、27。     

好算法：正确、效率、健壮、可读   

数据结构和算法(DSA)想要优化，首先需要测量     
算法分析两个方面：     
正确性：算法功能与需求是否一致，可能需要借助数学工具进行证明     
成本：运行时间和所需的存储空间     
这里更多关注时间成本     
如何度量？如何比较？
求解问题实例意义不大，因为可能的实例太多，如何归纳？
计算成本 **一般情况下** 和问题规模相关，一般是正相关

必实验统计是最直接的方法,但不足以准确反映算法的真正效率。
不同的算法,可能更适应于不同规模的输入。
不同的算法，可能更适应于不同类型的输入。
同一算法，可能由不同程序员、用不同程序语言、经不同编译器实现。
同一算法,可能实现并运行于不同的体系结构、操作系统...

需要抽象出一种理想的平台或模型:例如图灵机模型
Tape 依次均匀地划分为单元格各注有某一字符，默认可以为'#'   
Alphabet字符的种类有限   
Head 总是对准某一单元格，并可读取和改写其中的字符，每经过一个节拍，可转向左侧或右侧的邻格   
Transition Function: (q, C; d, L/R, p)若当前状态为q且当前字符为c，则将当前字符改写为d ;转向左侧/右侧的邻格;转入p状态；一旦转入特定的状态'h'则停机   
图灵机实例：将二进制非负整数加一：全'1'的后缀翻转为全'0'，原最低位的'0'或'#'翻转为'1'：     
(<，1, 0, L, <) //左行，1->0，可能多次使用    
(<, 0, 1, R, >) //掉头，0->1     
(<，#，1,R,>)  // 或者遇到# 翻转为1 
(>, 0, 0, R, >) //右行   
(>, #，#，L, h) //复位   
复位是因为这一段有可能是一个算法的一部分，需要反复使用，这是一种规范，多通过接口形式规定     

RAM(Random Access Machine)模型：做加法时，需要先将常数放进寄存器，再对寄存器进行相加     
与图灵机相同：寄存器顺序编号，总数没有限制；基本操作仅需常数时间；     
与TM模型一样，RAM模型也是一般计算工具的简化与抽象，使我们可以独立于具体的平台,对算法的效率做出可信的比较与评判，算法效率不取决于CPU的主频，而取决与CPU的计算次数     
在这些模型中，算法的运行时间可转化为算法需要执行的基本操作次数，衡量算法效率的函数T(n) = 算法为求解规模为n的问题,所需执行的基本操作次数。   

大 O 记号(big-o notation)，更关心足够大的问题，注重考察成本的增长趋势而不是某个运算过程的局部细节   
渐进分析：当问题规模足够大后，计算成本如何增长   
当 n 足够大，对与输入规模为n的算法：   
需执行的基本操作次数   
需占用的存储单元数（通常可不考虑）   
多项式复杂度，舍掉低阶项

T(n)=0(f(n)) iff 彐 c > 0，当n>>2后,有T(n) < c.f(n)      
反映T(n)的增长趋势，T(n)时间复杂度常系数意义上的的上界(经过常系数放大能构成上界)，局部值不一定小于T(n)     
常数项可以忽略，低次项可以忽略 O(sqrt_(35n³+7)) -> O(sqrt_36n³) -> O(6n<sup>1.5</sup>) -> O(n<sup>1.5</sup>)    
Ω与O相反，T(n) > c.f(n)，构成下界     
Θ确界，可看作Ω与O的组合，彐 C₁ > C₂ > 0，当n>>2后,有c₁×f(n) > T(n) > C₂×f(n)   

O(1) 常数复杂度     
O(logn) 对数复杂度，通常不考虑底数，因为通过对数运算，可以给logn增加一个常系数，使底数随意变化，O(logn...)的多项式多次方同样可舍掉低次方项   
这两种比较高效   

有效解：   
多项式复杂度，一般只需要保留最高次方，例：(~~2013~~n<sup>2</sup> - ~~20n~~)/(~~1999~~n - ~~1~~) = O(n<sup>2</sup>/n) = O(n)    
其中线性复杂度：规模为n复杂度为O(n)的   
O(n<sup>c</sup>)一般都认为是有效解，且并未对c做限制   

难解(无效解法，效率不可忍受)：   
指数复杂度：O(2<sup>n</sup>)   

subset,一个集合，分为两个，两个子集合中元素的和相等（个数可能不同），幂集(对所有元素选或者不选 2<sup>n</sup>)，比如美国选举，只有O(2<sup>n</sup>)的解法，它(2-Subset问题)是典型的NPC(NP-Complete 即:就目前的计算模型而言，不存在可在多项式时间[ O(n<sup>c</sup>) ]内回答此问题的算法)问题     

指数复杂度在小尺度的时候可能比某些多项式低，但增长速度快，在足够大的之后会超过所有固定阶次的多项式   

## 绪论（下）

估算，去粗存精   
算法分析的主要任务：正确性（不变性 × 单调性）+ 复杂度   
考察复杂度，不需要将算法描述为 RAM 的基本指令，在渐进意义下，C++等高级语言的基本指令与RAM相当   

迭代：级数：算数级数：T(n) = 1 + 2 + ... + n = n(n+1)/2 = O(n²)     
平方和：1² + 2² + ... + n² = n(n+1)(2n+!)/6 = O(n³)   
立方级数求和:1³ + 2³ + …… + n³ = [n(n+1)]²/4 = O(n<sup>4</sup>)   
4次方级数求和 : [n(n+1)(2n+1)(3n²+3n−1)]/30 = O(n<sup>5</sup>)   
https://saaavsaaa.github.io/jax/escape.html   
$$
\sum_{k=0}^{n}{k^d} ≈ ∫_0^nx^ddx = \frac{1}{d+1}n^{d+1} = O(n^{d+1}) 
$$   
几何级数：末项 https://mp.weixin.qq.com/s/OuPoTQ-DrgiTgGErXmBl9g    
a<sup>0</sup> + a<sup>1</sup> + ... + a<sup>n</sup> = (a<sup>n+1</sup> - 1)/(a - 1) = O(a<sup>n</sup>)   
1 + 2 + 4 + ... + 2<sup>n</sup> = 2<sup>n+1</sup> - 1 = O(2<sup>n+1</sup>) = O(2<sup>n</sup>)   

收敛级数：上界   
1 - 1/n = O(1)   
1 + 1/2² + ... + 1/n² = π²/6 = O(1)   
存储单元和操作不可能是分数，但可能是计算概率的、判断命中情况的几何分布：1/(1-λ) = O(1)   

未必收敛但项数有限:确界，**这两种很常用**   
1 + 1/2 + ... + 1/n = Θ(logn)   调和级数   
log1 + log2 + ... + logn = log(n!) = Θ(nlogn)   对数级数  

扩展阅读：《Concrete Mathematics》有很多相关内容，和其他复杂度情况介绍   

i=0;i<n;i++嵌套j=0;j<i;j++也是O(n²)  : 0 + 1 + ... + n-1 = n(n-1)/2，几何图形表示相当于一个三角形的面积，算数级数   
1.如果外循环的i++换成i <<= 1(代表左移一位，相当于×2)，几何级数，O(n) : 1 + 2 + 4 + ... + 2<sup>log<sub>2</sub>(n-1)</sup>   
2.如果内循环j++换成 j+j,∑<sub>0</sub><sup>i</sup>[log<sub>2</sub>i] = O(nlogn)，∑<sub>k=0...logn</sub>(k×2<sup>k-1</sup>) = O(logn × 2<sup>logn</sup>)   
数学上的级数通常是无限项, 但是在时间复杂度的计算中出现的级数, 通常是级数的有限项的和, 例如在数据规模为n的时候复杂度是级数的前n项   

找集合中的非极端元素，只需要随机选三个元素，取中间的那个，它就一定是非极端元素，无论集合多大：O(1)   Θ(1)   
气泡排序：嵌套循环   
正确性：有穷性：不变性:经k轮扫描交换后,最大的k个元素必然就位(一轮一个，一轮k次，第k大元素k次比较交换)；单调性:经k轮扫描交换后,问题规模缩减至n-k。正确性:经至多n趟扫描后，算法必然终止，且能给出正确解答。   

Back-0f-The-Envelope Calculation 封底估算   
CPU 一秒 gigahertz 10<sup>9</sup>，一天约10<sup>5</sup>(量级，估计 24×3600≈25×4000) sec，1世纪100年≈3×10<sup>9</sup>，“三生三世” ≈300 yr = 10<sup>10</sup> sec = (1 googel)<sup>1/10</sup> sec，宇宙大爆炸至今= 10<sup>21</sup> = 10×(10<sup>10</sup>)<sup>2</sup>     
全国人口普查排序估计：     
|      n = 10<sup>9</sup>     |   普通PC：1GHZ：10<sup>9</sup>次浮点运算      |     天河1A：千万亿次：1P：10<sup>15</sup>次浮点运算   |
|:--|:--|:--|
|  气泡排序 n² (10<sup>9</sup>)² |  10<sup>9</sup> sec [(10<sup>9</sup>)²÷10<sup>9</sup>] ： 30年 |     10<sup>3</sup> sec ： 20分钟    |
|  归并排序 nlogn 10<sup>9</sup>log<sub>2</sub>(10<sup>9</sup>) 30×10<sup>9</sup> |  30 sec |     0.03 毫秒   |


求n个数之和：循环O(n)，空间复杂度通常不计算输入的空间占用：O(2) O(1) 常数，循环，每次减少一个，子问题减少     
减而治之Decrease-and-conquer：为求解一个大规模的问题,可以将其划分为两个子问题:其一平凡，另一规模缩减。分别求解子问题，由子问题的解，得到原问题的解。     
递归跟踪( recursion trace) 分析检查每个递归实例，累计所需时间(调用语句本身,计入对应的子实例)，其总和即算法执行时间   
本例中，单个递归实例自身只需O(1)，时间T(n) = O(1) * (n+1) = O(n)，线性，最简单的递归形式，线性递归，可以使用递归跟踪方法分析     
递归跟踪:直观形象:仅适用于简明的递归模式   
###### 递推方程:间接抽象.更适用于复杂的递归模式   
从递推的角度看,为求解sum(A, n) ,需递归求解规模为n-1的问题sum(A，n-1)再累加上A[n-1],递归基: sum(A，0)     
递推方程:T(n) = T(n-1) + O(1)   T(0) = O(1)
求解：T(n) - n = T(n-1) - (n-1) = T(n-2) - (n-2) = ... = T(2) - 2 = T(1) - 1 = T(0) - 0
      T(n) = O(1) + n =  O(n)   

分而治之[Divide- and-conquer]：为求解一个大规模的问题,可以将其划分为若干(通常两个)子问题,规模大体相当，分别求解子问题，由子问题的解,得到原问题的解   
例：数组求和，递归分两段分别求和，直到每小段和只剩一个元素，T(n) = 各层递归实例所需时间之和 = O(1) x(2<sup>0</sup> + 2<sup>1</sup>+2²+..+ 2<sup>logn</sup>) = O(1) x (2<sup>logn+1</sup> - 1) = O(n)。更简单的方法：画成递归跟踪图实际就是二叉树的形式，每次递归分两段，叶子节点数的阶；它就是个公比为2的几何级数，几何级数与末项同阶(2<sup>logn</sup>)。递推方法：每个分两个+ 递归基的常数c [O(1)] 时间:T(n) = 2 * T(n/2) + c = 2²[T(n/4) + c]... = 2<sup>logn</sup>[T(1) + c] = n(c<sub>t</sub> + c)，(2<sup>log₂n</sup>=n)     
数组求其中最大的两个值，由最好n-1、最坏2n-3优化，二分递归最差T(n) = 2 * T(n/2) + 2, 左右加2(二分以后各自比较2 * 1)，T(n) + 2 = 2*[T(n/2)+2] = 2²*[T(n/4)+2] = ... = 2<sup>k</sup> * [T(n/k)+2],k=logn。当数组只有两个元素T(2) = 1，只有三个元素T(3) <= 3。递归基最差情况T(3) = 3，规模为n的二分递归第一次分n/2个、第二次分n/2²个、第n次分/n2<sup>logn</sup>个，每个最差3次，也就是说n/2<sup>k</sup> = 3，2<sup>k</sup> = n/3，T(n) + 2 = 2<sup>k</sup> * [T(n/k)+2] = n/3 * (T(3)+2)，T(n)=5n/3-2。实际上任何形式上满足 T(n) = k * n - 2 的通项公式都可以满足递归式T(n) = 2 * T(n/2) + 2。但是这里要带入初始条件即 T(3) <= 3, 由此可推出 T(n) <= (5/3)n - 2。   

http://dsa.cs.tsinghua.edu.cn/~deng/ds/dsacpp/?from=singlemessage
DSA 设计与优化的一种重要手段：动态规划   
递归可以满足work和right，但有时候不够快，从某种角度来说，动态规划从某种意义上将，也可以理解为先用递归找出算法的本质并给出一个初步的解，再等效的转化为迭代提高效率   
https://github.com/saaavsaaa/warn-report/blob/master/src/test/java/cn/tellwhy/structure/FibonacciTest.java   
递推关系：T(n) = T(n-1) + T(n-2) +　1, n > 1 , T(0) = T(1) = 1　　
设 S(n) = [T(n) + 1] /2   
则 S(0) = 1 = fib(1)，S(1) = 1 = fib(2)   
故 S(n) = S(n-1) + S(n-2) = fib(n+1) 复杂度O(Φ<sup>n</sup>)  Φ:斐波那契数列通项黄金分割，空间复杂度O(n)      
S(n)相当于fib(n+1)向后推了一项   
T(n) = 2 * S(n) - 1 = 2 * fib(n+1) - 1 = O(fib(n+1)) = O(Φ<sup>n</sup>) = O(2<sup>n</sup>)   Φ严格比1大,它的递归算法复杂度也呈现出斐波那契数列形式      
封底估算：     
Φ<sup>36</sup> = 2<sup>25</sup>   *=>*  算出第43项 ：Φ<sup>43</sup> = 2<sup>30</sup>  ≈  10<sup>9</sup> flo（条基本指令） = 主流PC 1 sec      
Φ<sup>5</sup> = 10   *=>*  Φ<sup>67</sup>  ≈  10<sup>14</sup> flo  =  10<sup>5</sup> sec = 1 day     
Φ<sup>92</sup> ≈ 10<sup>19</sup> flo = 10<sup>10</sup> sec = 10<sup>5</sup> day = 3 century 相当于在有穷时间内得不到结果，严格来说都不能算是算法     
递归版fib()低效的根源在于，各递归实例均被大量重复地调用。每算一项，都要分别递归计算出其前两项，而实际上没必要分别算，因为可以用n-1项算出第n项   

解决方法A (记忆: memoization)将已计算过实例的结果制表备查     
解决方法B (动态规划: dynamic programming)颠倒计算方向:由自顶而下递归，为自底而上迭代。T(n) = O(n) ,而且仅需O(1)空间（保存当前的两个值）     
最长公共子序列：两个序列中同时存在的序列中最长的(可能不唯一)，序列中的字符可以不相邻，但是顺序必须一致     
递归：必对于序列A[0, n]和B[0, m], LCS(A, B)无非3种情况：     
0)若n=-1或m=-1,则取作空序列(”“)  ： 递归基     
1)若A[n] = 'X'= B[m]，则取作LCS(A\[0, n), B\[0, m)) + 'X' ：  减而治之   
2) A[n] ≠B[m]，则在LCS(A[0, n], B[0, m))与LCS(A[0， n), B[0，m])中取更长者。A或B的尾字符无用两种情况，用A和B分别递归这两种情况。     
正确性可以保证，因为单调性:无论如何,每经过一次比对,原问题的规模必可减小，具体地，作为输入的两个序列，至少其一的长度缩短一个单位
最好情况(不出现第2种情况)下，只需O(min(m,n))时间   
但问题在于，(在第2种情况)原问题将分解为两个子问题，更糟糕的是,它们在随后进一步导出的子问题,可能雷同(子问题虽然不同，但是子问题的子问题可能相同，但在不同的递归子问题中，公共子问题会被重复计算)   
在最坏情况下，LCS(A[0，a], B[0，b])出现的次数为: C(n+m-a-b, n-a) = C(n+m-a-b,m-b) 矩形格路模型中所有可能路径的组合，当a=b=0时：C(n+m, n) = C(n+m,m)，当n=m时，O(2<sup>n</sup>)     
与fib()类似，这里也有大量重复的递归实例(子问题)，(最坏情况下)先后共计出现O(2<sup>n</sup>) 个     
各子问题，分别对应于A和B的某个前缀组合，因此总共不过0(n * m)种，采用动态规划的策略，只需0(n * m)时间即可计算出所有子问题。为此，只需：     
0)将所有子问题(假想地)列成一张表     
1)颠倒计算方向，从LCS(A[0], B[0])出发，依次计算出所有项     

递归:设计出可行且正确的解     
动态规划:消除重复计算，提高效率     

## 向量（上）     
抽象数据类型 = 数据模型 + 定义在该模型上的一组操作     
数据结构 = 基于某种特定语言，实现ADT的一整套算法     
向量：常见语言中数组的抽象与泛化     
C/C++语言中，数组A[]中的元素与\[0，n)内的编号一一对应。每个元素均由(非负)编号唯一指代,并可直接访问    
A[i]的物理地址 = A + ixs, s为单个元素占用的空间量，故亦称作线性数组( linear array )     
向量是数组的抽象与泛化，由一组元素按线性次序封装而成     
各元素与\[0，n)内的秩( rank)一一对应;//循秩访问( call-by-rank )     
元素的类型不限于基本类型     
操作、管理维护更加简化、统一与安全     
可更为便捷地参与复杂数据结构的定制与实现     
向量ADT接口(不用记)
|操作 |功能|适用对象|
|:-:|:--|:--|
|psize( )|报告向量当前的规模(元素总数)|向量|
|get(r)|获取秩为r的元素|向量|
|put(r, e)|用e替换秩为r元素的数值|向量|
|insert(r, e)|e作为秩为r元素插入,原后继元素依次后移|向量|
|remove(r)|删除秩为r的元素,返回该元素中原存放的对象|向量|
|disordered()|判断所有元素是否已按非降序排列|向量|
|sort()|调整各元素的位置，使之按非降序排列|向量|
|find(e)|查找目标元素e|向量|
|search(e)|查找目标元素e, 返回不大于e且秩最大的元素, 重复元素返回rank最大的，比全局都小且不存在返回-1(假设-1位置值是-∞)|有序向量|
|deduplicate()|剔除重复元素|向量|
|uniquify()|剔除重复元素|有序向量|
|traverse( )|遍历向量并统一处理所有元素,处理方法由函数对象指定|向量|

若采用静态空间管理策略,容量capacity固定,则有明显的不足     
1.上溢(overflow) :\_elem[]不足以存放所有元素     
尽管此时系统仍有足够的空间     
2.下溢( underflow) :\_elem[ ]中的元素寥寥无几     
装填因子( load factor) λ = \_size/\_capacity << 50%     

动态空间管理     
在即将发生上溢时，适当地扩大内部数组的容量 T* oldElem = \_elem; \_elem = new T\[\_capacity <<= 1];//容量加倍     
得益于向量的封装,尽管扩容之后数据区的物理地址有所改变,却不致出现野指针     

为何必须采用“容量加倍”的策略呢?     
不加倍的情况     
每次增加I， 最坏情况:在初始容量0的空向量中，连续插入n = m * I >> 2个元素...     
于是，在第1、I+1、2I+1、3I+1、...次插入时，都需扩容     
即便不计申请空间操作，各次扩容过程中复制原向量的时间成本依次为 0, I, 2I, .... (m-1)I     
总体耗时 = I * (m-1) * m/2 = O(n²) ，每次扩容的分摊成本为O(n)     
装填因子逐渐接近100%

容量加倍     
最坏情况:在初始容量1的满向量中,连续插入n = 2<sup>m</sup> >> 2个元素...     
于是，在第1、2、4、8、16、.. .次插入时都需扩容     
各次扩容过程中复制原向量的时间成本依次为     
1,2,4,8,....2<sup>m</sup> = n                   //几何级数     
总体耗时 = O(n) ，每次扩容的分摊成本为O(1)     
装填因子 至少 > 50%，牺牲空间换时间     

平均分析 vs.分摊分析     
平均复杂度或期望复杂度( average/expected complexity)     
根据数据结构各种操作出现概率的分布,将对应的成本加权平均     
缺点：各种可能的操作，作为独立事件分别考查，割裂了操作之间的相关性和连贯性，往往不能准确地评判数据结构和算法的真实性能     

分摊复杂度( amortized complexity )     
对数据结构连续地实施足够多次操作,所需总体成本分摊至单次操作     
从实际可行的角度，对一系列操作做整体的考量，更加忠实地刻画了可能出现的操作序列，可以更为精准地评判数据结构和算法的真实性能     

向量插入的操作，右移是从尾部开始向前的，在有必要的情况下扩容     
区间删除中的左移是由头至尾、从前向后的次序前移，同样是为了避免元素覆盖，必要情况下缩容（通常可忽略），区间删除可以清空再移动过，也可以直接将右侧元素覆盖到待删元素上并改变算组结尾指针位置，不删一个移动一个是因为每删一个就全移动最差有O(n²)的复杂度     

查找：     
对于无序向量: T为可判等的基本类型，或已重载操作符"=="或”!="     
对于有序向量: T为可比较的基本类型,或已重载操作符"<"或">"     
挨个循环最差O(n)，这种最好和最差相差悬殊的算法叫输入敏感( input-sensitive ) 算法，它具体的复杂度与输入时的分布紧密相关     

唯一化：去重。
循环找对当前元素去重，这个方法复杂度很高。正确性：不变性:在当前元素V[订]的前缀V\[0，i)中 ，各元素彼此互异，初始i = 1时自然成立:其余的一般情况，...。单调性:随着反复的while迭代：1 )当前元素前缀的长度单调非降，且迟早增至_ size //1)和2)对应；2)当前元素后缀的长度单调下降，且迟早减至0 //2)更易把握。故算法必然终止，且至多迭代0(n)轮     
每轮迭代中 find()和 remove()累计耗费线性时间,故总体为O(n²)。find对当前元素前缀（之前是否找到了重复的），remove对后缀（删了重复的，后面元素依次前移），两个操作互补是整个数组长度，所以每次while循环不会超过O(n)。     
可进一步优化，比如：     
1.仿照 uniquify( )高效版的思路，元素移动的次数可降至O(n)，但比较次数依然是O(n²) ;而且,稳定性将被破坏。     
2.先对需删除的重复元素做标记,然后再统一删除。稳定性保持,但因查找长度更长,从而导致更多的比对操作     
3. V.sort().uniquify() :简明实现最优的O(nlogn)     
先排序，然后用一个全局变量记录需要前移的值，每删(值置为空，后续讲高效的时候，老师是直接忽略，因为会覆盖，多余的会通过size去除，我是习惯置空)一个元素，将需要前移的值+1，当遇到待移动值(删除后不移动等到遇到不同元素才移动这个不同元素)，按照当前记录的需要前移的值移动，最终更新数组长度。由于相同元素都相邻，所以对比到不同元素，就代表当前元素比较结束，开始比下一个，比较次数由向量长度决定

#### 有序向量：     
有序/无序序列中，任意/总有-对相邻元素顺序/逆序     
因此，相邻逆序对的数目,可用以度量向量的 **逆序程度**      
元素可比较，即可转为有序，通常处理为有序后，相关算法多可优化     
有序的去重，如果是每删一个就移动一次，最坏的情况下，所有元素都相同O(n²)     
反思:低效的根源在于，同一元素可作为被删除元素的后继多次前移     
启示:若能以重复区间为单位,成批删除雷同元素,性能必将改进     
共计 n-1饮迭代,每次常数时间,累计O(n)时间     

#### 二分查找
语义约定     
至少，（比如search接口）应该便于有序向量自身的维护: v.insert(1 + v.search(e), e)，插入首先要找一个适当的插入顺序，如1 + v.search(e)     
即便失败,也应给出新元素适当的插入位置     
若允许重复元素,则每一组也需按其插入的次序排列     
约定:在有序向量区间V\[1o, hi)中,确定不大于e的最后一个元素     
二分：一半的下整     
这里是减而治之不是分而治之，因为每次都忽略掉了至少一半规模的问题，而不是分成几份分别处理       
判断写代码时建议用小于号，因为小于号与平时从左到右从小到大的习惯符合       
线性递归: T(n) = T(n/2) + O(1) = O(1ogn)，大大优于顺序查找     
递归跟踪:轴点总取中点,递归深度O(1ogn) ;各递归实例均耗时O(1)     
如何更为精细地评估查找算法的性能?     
考查关键码的比较次数,即查找长度( search length )     
通常，需分别针对成功与失败查找，从最好、最坏、平均等角度评估     
比如，成功、失败时的平均查找长度均大致为 O(1.501ogn)，用比较次数÷可能的命中情况的情况数，结果再除以以2为底向量长度的对数，得大约1.5      
如果元素刚好在正中，需要先比较左侧和右侧元素，多两次比较     

## 向量（下）
二分查找版本A的效率仍有改进余地，因为不难发现转向左、右分支前的关键码比较次数不等,而递归深度却相同     
若能通过递归深度的不均衡，对转向成本的不均衡进行补偿，平均查找长度应能进一步缩短     
比如，若设 n = fib(k)-1.则可取 mi = fib(k-1)-1     
于是，前、后子向量的长度分别为 fib(k - 1) - 1、fib(k- 2) - 1     
与二分查找唯一的区别在于初始化为斐波那契数列形式，每次比较不是取中间项，而是黄金分割比例项，也就是第斐波那契数列项前一项的索引位置的数，由高向低，由这个前一项做切分点      
Fibonacci查找的ASL，(在常系数的意义上)优于二分查找 //详见教材、习题解析     
仍以n = fib(6) - 1 = 7为例，在等概率情况下     
平均成功查找长度=(5+4+3+5+2+5+4)/7=28/7= 4.00 括号中的数代表在某个位置查找成功所需的比较次数 < 二分查找 4.14     
平均失败查找长度= (4+5+4+4+5+4+5+4)/8=35/8=4.38 < 二分查找 4.50     
通用策略:对于任何的A[0, n)],总是选取A[λn]作为轴点，0 ≤ λ < 1     
比如:二分查找对应于λ=(0.5), Fibonacci查找对应于λ = φ = 0.6180339..     
在\[0，1)内，λ如何取值才能达到最优?设平均查找长度为α(λ)log₂n，何时α(λ)最小?     
递推式: α(λ).log₂n= λ.[1 + α(λ).log₂(λn)] + (1-λ).[2 + α(λ).log₂((1-λ)n)]     分两段，如果每个元素命中概率相同，则在左侧命中的概率为λ右侧1-λ     
求极值当λ=φ时，α(λ)= 1.440420...达到最小，二分是1.5     

#### 二分查找(改进)
二分查找中左、右分支转向代价不平衡的问题,也可直接解决     
比如,每次迭代(或每个递归实例)仅做1次关键码比较     
如此，所有分支只有2个方向，而不再是3个     
同样地，轴点mi取作中点,则查找每深入一层,问题规模也缩减半     
1\) e < x : 则e若存在必属于左侧子区间S\[1o， mi)，故可递归深入     
2\) x <= e : 则e若存在必属于右侧子区间S\[mi, hi)，亦可递归深入     
只有当元素数目hi - lo = 1时，才判断该元素是否命中     
相对于原版本，最好(坏)情况下更坏(好) ;各种情况下的SL更加接近,整体性能更趋稳定(原版本好坏情况性能差异很大)     
以上二分查找及Fibonacci查找算法
均未严格地兑现search( )接口的语义约定):返回不大于e的最后一个元素
只有兑现这- -约定，才可有效支持相关算法，比如: v.insert(1 + v.search(e)， e)     
1 )当有多个命中元素时,必须返回最靠后(秩最大)者     
2 )失败时，应返回小于e的最大者(含哨兵[1o - 1] )     
新版本再稍加改动：     
1 )待查找区间宽度缩短至0而非1时,算法才结束     
2 )转入右侧子向量时,左边界取作mi + 1而非mi，因为严格小于进左侧，严格大于就是右侧，右侧如果找不到就返回mi，而mi要么命中要么符合前一个元素这一语义      
3 )无论成功与否，返回的秩严格符合接口的语义约定，返回当前位置的前一个元素     

#### 有序向量：插值查找
假设:已知有序向量中各元素随机分布的规律。比如: **均匀且独立的随机分布**     
于是: \[1o, hi)内各元素应大致按照线性趋势增长，元素比约等于秩的比，因此:通过猜测轴点mi，可以极大地提高收敛速度     
例如:在英文词典中（设每个字母所占页数大致相同）：     
binary大致位于2/26处     
search大致位于19/26处     
例：1o=0，hi=18，数组A，带查找的e=50

|秩：|0 |1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 | 9 | 10| 11| 12| 13| 14| 15| 16| 17| 18|
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
|元素：|5 |10 |12| 14| 26| 31| 38 |39| 42| 46| 49| 51| 54| 59 |72| 79| 82| 86| 92|

第一次查找：     
插值:mi = lo +（hi－lo）* (e - A[lo]) / (A[hi] - A[lo]) = 0 + (18-0) * (50-5)/(92-5) = 9.3     
取: mi = 9      
比较:A[9] = 46 < e     
于是，排除前9个元素，lo=10，hi=18，第二次查找：     
插值: mi = 10 + (18 - 10) * (50 - 49)/(92 - 49) ≈ 10.2
取: mi=10     
比较:A[10] = 49 < e     排除第10个元素     
lo=11,hi=18     
插值: mi = 11+ (18 - 11) * (50 - 51)/(92 - 51) = 10.8     
取: mi = 10 < lo     
查找完成( NOT_ FOUND )     
只比较了三次     
最坏情况: O(hi - 1o) = O(n)     
最好情况:稍试即中、初试即中     
平均情况:每经一次比较，n缩至n<sup>1/2</sup> //[Ya076， PIA78]，习题解析[2-24]有证明     
于是,待查找区间宽度将按以下趋势缩减: n, n^(1/2), n^(1/2)², .... n^(1/2)<sup>k</sup>, .... 2     
经多少次比较之后,有 n^(1/2)<sup>k</sup> < 2 ?     
(1/2)<sup>k</sup> * logn < 1     
k * 1og(1/2) + loglogn < 0     
-k + 1oglogn < 0 或 k > loglogn     
所以复杂度：O(log<sup>logn</sup>)       
也可以用推算，对n开方，对logn复杂度就是1/2 * logn，对logn每次都折半，平均到每次就相当于logn的log     
补充：这里课上说的字长是指二进制位     
从O(1ogn)到O(loglogn)，是杏值得     
通常优势不明显，除非查找区间宽度极大，或者比较操作成本极高     
比如，n = 2^(2^5) =(2^32)= 4G时，1og(n) = 32，log(1og(n)) = 5     
它缺点是易受小扰动的干扰和“蒙骗”，在局部花费很多时间     
而且它须引入乘法、除法运算，而乘除法的运算成本更高     
实际可行的方法：在极大规模上，首先通过插值查找,将查找范围缩小到一定的范围，然后再进行二分查找     
大规模:插值查找     
中规模:折半查找     
小规模:顺序查找     
可以根据情况组合使用

#### 起泡排序
void Vector<T>:t sort(Rank 1o, Rank hi) { //区间[1o, hi)     

case 1 : bubbleSort(lo, hi); break; //起泡排序     
case 2 : selectionSort(lo, hi); break; //选择排序 (习题)     
case 3 : mergeSort(lo, hi); break; //归并排序     
case 4 : heapSort(lo, hi); break; //堆排序(第10章)     
default: quickSort(lo, hi); break; //快速排序 (第12章)     

bubbleSort：
O(n²) 改进，序列可能局部有序，最小元素在最右侧无法优化     
改进一：判断起泡排序的一次循环中是否有逆序对存在，如果未发生元素顺序交换，则停止循环直接完成，不一定要完全按n的个数循环完，逆序部分长度r则O(n * r)     
改进二：记录最右一个逆序对的位置，将循环的右边界指向这个位置，每次只循环边界内的     
效率与第一章针对整数数组的版本相同，最好O(n)，最坏O(n²)，优化针对一般情况，一定概率上更好    
输入含重复元素时,算法的稳定性( stability )是更为细致的要求，重复元素在输入、输出序列中的相对次序，是否保持不变?
在起泡排序中,元素a和b的相对位置发生变化，只有一种可能:经分别与其它元素的交换，二者相互接近直至相邻。在接下来一轮扫描交换中，或者因逆序而交换位置     

#### 归并排序
常规的基于比较式的算法(comparison based algorithm，CBA)，求解排序问题都存在一个下界Ω(nlogn)     
// 分治策略      
//向量与列表通用     
//第一次编码实现（思想更早就出现了） J. von Neumann, 1945     
序列一分为二 // O(1)     
子序列递归排序//2 x T(n/2)  
合并有序子序列// O(n)     
无序向量的递归分解，到每个元素成为独立的子序列后，就抵达了递归基       
独立后就有序了(只有一个)，然后是有序向量逐层归并     
T(n) = 2T(n/2)+ O(n)      -->   O(nlogn)     
一分为二和递归都很简单，核心在于合并     
二路归并






-----

[edit](https://github.com/saaavsaaa/saaavsaaa.github.io/edit/master/aaa/Structure_Abstract.md)
