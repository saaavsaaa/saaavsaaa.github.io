&nbsp;&nbsp;前略：[Paddle 入门](https://saaavsaaa.github.io/aaa/Paddle_Begin.html) 中用了线性回归的模型，模型本身十分简单，那么用于训练的输入数据就十分重要，而手头上有的数据也是各种各样，对数据的特征提取对于此类模型十分重要，我感觉也是真正开始的第一步(似乎应该先做一下探索性数据分析，特别是对业务不熟悉的情况下，不过回头再说)，虽然我开始都直接用的占比。以下内容来源于《美团机器学习实践》，百度百科，以及各种没记下来来源处的阅读笔记。     

&nbsp;&nbsp;对不同类型数据的提取：     

&nbsp;&nbsp;&nbsp;&nbsp;数值类型：   

```markdown

      截断:降低精度；     
      二值化:由于计数累加可能极快。处理计数特征时首先要考试是保留原始计数、转为二值变量来标识是否存在或者进行分桶。     
      分桶:当数值跨越不同的数量级。有些模型对比较大的数值敏感，这种情况下常见的方法就是分桶，可以固定宽度均匀分桶，可以根据10的幂次，也可以基于数据分布或使用模型例如聚类的方式将特征分为多个类别。由于计算是对桶进行的，系数是根据桶运算出的，特征的表现形式，分桶并不会影响正确性。     
      缩放:将数据按比例缩放，使之落入一个小的特定区间。
           标准化缩放(z-score):一个分数与平均数的差再除以标准差，公式为z=(x-μ)/σ。其中x为某一具体分数， μ为平均数，σ为标准差。其中μ为总体平均值，x-μ为离均差，σ表示总体标准偏差，Z值的量代表着原始分数和母体平均值之间的距离，是以标准差为单位计算的 —— 一个给定分数距离平均数多少个标准差。当原始分数低于平均值时，z为负，高于平局值为正。一个数列的各z分数的平方和等于该数列数据的个数，并且z分数的标准差和方差都为1.平均数为0。z分数是一种可以看出某分数在分布中相对位置的方法。将成正态分布的数据中的原始分数转换为z分数，就可以通过查阅z分数在正态曲线下面积的情况来得知平均数与z分数之间的面积，进而得知原始分数在数据集合中的百分等级。适用于目标变量为输入特征的光滑函数的模型,线性回归、逻辑回归等。归一化方式要求原始数据的分布可以近似为高斯分布，在不涉及距离度量、协方差计算、数据不符合正太分布时效果不佳。     
           最大最小值归一化:将原始数据线性化的方法转换到[0，1]的范围，公式X<sub>normalize</sub>=(X-X<sub>min</sub>) / (X<sub>max</sub>-X)。缺点是抗干扰能力弱，受离群值影响比较大，会有缺失数据，有新的输入值时可能会受到输入值影响。最大绝对值归一化，使用绝对值最大的数除。还有移动小数点的小数定标方法也是根据最大值绝对值，最大值绝对值多少位就移动多少位。     
           还有基于范数的归一化，如L0范数是指向量中非0的元素的个数；L1 范数(向量中各个元素绝对值之和，L1范数是L0范数的最优凸近似。任何的规则化算子，如果他在Wi=0的地方不可微，并且可以分解为一个“求和”的形式，那么这个规则化算子就可以实现稀疏。W的L1范数是绝对值，|w|在w=0处是不可微。L0也可以实现稀疏，但是实际中会使用L1取代L0。在支持向量机（support vector machine）学习过程中，实际是一种对于成本函数(cost function)求解最优的过程，因此，L1范数正则化通过向成本函数中添加L1范数，使得学习得到的结果满足稀疏化(sparsity)，从而方便人们提取特征);L2范数是指向量中各元素的平方和然后开方。L1会趋向于产生少量的特征，其他的特征都是0，而L2会选择更多的特征，这些特征都会接近于0。越小的参数说明模型越简单，越简单的模型则越不容易过拟合(在对模型进行训练时，有可能遇到训练数据不够，即训练数据无法对整个数据的分布进行估计的时候，或者在对模型进行过度训练（overtraining）时，常常会导致模型的过拟合（overfitting），即模型复杂度比实际数据复杂度还要高)。     
           平方根缩放或对数缩放:对数缩放对于处理长尾分布(齐普夫定律，不太理解回头实际做做看)且取值为正数的数值变量非常有效，它将大端长尾压缩为短尾，并将小端进行延伸，平方根或者对数变换是幂变换的特例，在统计学中都称为方差稳定的变换，其中Box-Cox变换是简单的幂变换，Box-Cox转换仅对取值为正数的数值变量起作用。Box-Cox的一般形式是个分段函数，当λ=0时，y(λ)=lny，当λ≠0时y(λ)=(y<sup>λ</sup>-1)/λ，y(λ)为经Box-Cox变换后得到的新变量，y为原始连续因变量，λ为变换参数。以上变换要求原始变量y取值为正，若取值为负时，可先对所有原始数据同加一个常数a使其(y+a)为正值，然后再进行以上的变换。对不同的λ所作的变换不同。在λ=0时该变换为对数变换,通常用于呈正偏分布的数据，其中有些值非常大，如果这些大值位于研究区域中，对数变换有助于使方差更加恒定和归一化数据;λ=-1时为倒数变换;而在λ=0.5时为平方根变换。Box-Cox通常会使数据呈正态分布。Box-Cox变换中参数λ的估计有两种方法：(1)最大似然估计；(2)Bayes方法。通过求解λ值，就可以确定具体采用哪种变换形式。(这一段参考的比较杂，没有实际应用过，没什么感觉)    
           对于有异常点的数据，还可以使用中位数而不是均值，基于分位数而不基于方差(分位数亦称分位点，是指将一个随机变量的概率分布范围分为几个等份的数值点，常用的有中位数即二分位数、四分位数、百分位数等)。

```
