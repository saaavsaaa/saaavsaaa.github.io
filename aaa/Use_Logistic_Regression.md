最近在做商品推荐功能,最开始打算直接用RFM模型,给每个商品的客户价值做排序,然后发现行不通,因为上千的商品,各种各样类型,可是我没有渠道能得到模型中各个维度的权重,很多结果很微妙。于是，我换了个思路，由于之前做探索性分析的时候发现我们的数据可操作的空间不大，行业比较特殊，可借鉴的经验也很少，当时就想，我直接对用户聚类，从结果中分出用户购买与未购买的比例做先验概率，然后根据新下单情况套贝叶斯。然而实际开始做了才发现比我想的要复杂的多，还参照了不少论文自己开发了个合适我们场景的聚类算法。   

然后突然有一天想到，其实我可以先弄个简单模型验证一下，数据间是不是有比较直接相关性，如果有就先弄个简单的模型上去跑着看效果。如果效果好，原来的思路可以为了其他功能慢慢做，这边不断优化简单的模型。而这个简单的模型，我就准备用逻辑回归，如果好就该支持向量机，我们的数据情况正好也适合支持向量机，再之后还可以用神经网络。补充一下：一般虽然做商品推荐很多都是协同过滤之类，但是我们的数据比较有意思，并不适合。     

那么，正文开始，首先选择逻辑回归有一个假设前提：用户数据和商品数据与该用户对该商品下订单间有统计规律。毕竟一堆数据给一个优秀的统计学家，如果这个统计学家都无法从数据中得出什么，那算法恐怕也没用。这个前提是不是成立就很好验证了，只要看训练出来的模型在测试集上的表现就可以了。

于是整个开发过程中，最费劲的部分就开始了，好在特征工程在之前思路的开发中已经做差不多了，只需要重新选定特征，看情况调一调就好了。这里做了独热，对日期做了些处理，还有一些不方便说的特殊种类字段的值的转换，再就是null值的处理（根据总体数据中null值的比例）、均值归一什么的。数据集的选取中，用户数据从总数据中随机选了1000数据可信度比较高的，商品信息清理了9000，两个集合做笛卡儿积，然后看用户是否买过对应商品作为预测值。我觉得这里其实有个坑，一个下过单的用户我预测了他这次下单，其实他下不下单都不能说模型是错的，不过毕竟是简单的验证数据间的关系，开始的假设过于随意了，之后再来调整模型解决这个问题。

训练集97%到测试集就只有90%左右的准确率，这应该是过拟合了，然后就是反复增减维度，试验，画梯度下降、学习曲线这些，然后根据一堆曲线调，然而调了以后虽然测试集效果是很好了，但是用同事筛出来的数据又不理想了。因为我们数据源不太一样，而且为了收集足够的维度，我排除了一些数据；另外就是我们商品类别实在太多了，对指定的客户推荐商品应该是按每一类商品去跑个模型，比如快消品和奢侈品肯定偏向是不同的，这个简单的模型过于简单了。
