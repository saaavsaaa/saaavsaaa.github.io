Kaldi是围绕隐马尔科夫模型的，“端到端”可以不需要隐马尔科夫模型，混合神经网络，双向长短记忆神经网络+CTC目标函数

Y是输入音频，w是真正的词序列，求最大的P(w|Y)。由贝叶斯可得P(w|Y) = P(Y|w)P(w)/P(Y)。其中Y为确定值，于是P(Y)为常数，求极值时可以忽略。     
对P(Y|w)和P(w)分开建模：     
P(Y|w)在给定单词序列w时，可以得到特定音频信号Y的的概率，通常称为声学模型。    
P(w)给定单词序列w的概率。通常称为语言模型。     
Y通常每隔10毫秒在25毫秒的时间窗口中提取一个特征向量，输入概率模型的Y实际中通常是一系列特征向量的序列    
单词序列w通常会拆成一个音素序列     
Q是单词序列w对应的发音单元序列，这里简化为音素序列，那么声学模型p(Y|w)=∑p(Y|Q)P(Q|W)，这个求和是单词序列w对应的所有可能得音素序列Q的集合计算边缘分布概率。于是声学模型就拆分成P(Y|Q)和P(Q|w)。特征向量|音素、音素|词序列     
（第九页）P(Q|w)：w中每个词发音为q的概率乘积。单词可能有多个发音，但通常多音词的发音不会很多，因此P(Q|w)比较容易从发音词典中计算出来。注：多音词不是带有多音字的词，多音词不同发音意义不同     
P(Y|Q)是声学模型的核心，Q中每一个音素构建一个隐马尔科夫模型单元，根据Q的音素序列拼成一个句子级别的的隐马尔科夫模型，特征序列Y是隐马尔可夫模型的可观察输出。实际中要复杂一些，比如使用上下文三音子作为隐马尔科夫单元     
P(w)，用前n-1个词预测第n个词，n一般取3、4，已知w0...w(l-1)，下一次是wl的概率     

### 语音信号处理：     
音频采样：采样记录电流值，两次采样的间隔称为采样周期，它的倒数是采样频率。例如每隔1/16000秒采样一次，采样频率为16000Hz。    
量化：11页，样点格式转化     
回声消除    
噪声抑制：频域抑制、空域抑制     
动态增益控制     
音频编解码：主要用于网络传输     
其中，采样和量化是声音信号转换为计算机数据必不可少的方法     

发音和语言学：人类语音答题可分为有限的若干基本元素，称为音素    
发音词典：表意单元与音素组合之间的映射。音素是人为定义概念，所以不同语言有不同的音素集，不同的发音词典。汉语常用拼音，由于多音字和多音词，发音词典并不一一映射。除语音音素，通常还要加入非语音音素如静音音素、噪音音素等。          
实际中，还要考虑上下文影响造成的协同发音。喝多技术都是为了处理协同发音，例如：每个音素往往分为多个状态，分别对应不同的发音阶段，不同阶段的差异主要是受上下文的相邻音素影响。再比如，对每个音素建模时，建模对象实际上是由上下文音素组成的三音子(Triphone)组合。     

语音识别评价：错误率(插入、删除、替换)、正确率、实时率(耗时÷句子时长)。错误率可能大于100%。     


### Kaldi集群    
小型集群：
需要子任务进程对同一目录有读写权限，需要搭建网络文件系统(NFS),需要确保同一用户在不同机器上使用相同的UID和GID：id -u xxx和id -g xxx     
完成NFS后，在要加入集群的机器上设置互相之间的免密登录，确认NFS的挂载点在所有机器上有相同的访问权限     
大型集群：
Kaldi支持：SGE(Sun Grid Engine) 和 SLURM(Simple Linux Utility for Resource Management)，默认用SGE，但书上推荐自己维护的读者使用SLURM。     

### 脚本解析：     
utils/run.pl 这个Perl脚本的作用是用多任务执行某个程序，可以独立于Kaldi之外使用。在steps的train_mono.sh、decode.sh等很多脚本都可以通过cmd参数使用它。   
utils/run.pl JOB=1:n(数字) /...(路径)/log.JOB.txt echo "This is a job JOB"     该命令同时执行n个echo命令，并发屏幕显示分别写入log.[1-n].txt这n个文本中     
Kaldi提供了 run.pl、queue.pl 和 slurm.pl。     
数据整理主要有两个目的，一是整理成Kaldi规范的数据文件夹格式；二是划分测试集和训练集。     
每个句子被指定了一个唯一ID   
wav.scp 记录每个ID的音频文件路径   
text 记录每个ID的文本内容
spk2utt 和 utt2spk 记录每个ID的说话人信息   
还需要手工准备：   
发音词典 lexicon.txt   
lexicon_nosil.txt 和 lexicon类似，只是去掉了<SIL>   
phones.txt 音素集，也可硬从lexicon.txt 文件中的所有音素去重得到   

task.arpabo 语言模型   

prepare_lang.sh 生成语言文件夹 data/lang 存储了待识别的单词集、音素集等信息
local/prepare_lm.sh 把语言模型构建成图   

接下来是定义声学特征，它是训练声学模型的基础：执行完生成 feats.scp 记录了声学特征的存储位置   
steps/make_mfcc.sh compute_cmvn_stats.sh utils/fix_data_dir.sh

之后是声学模型训练和测试,steps/train_mono.sh   

识别也叫解码steps/decode.sh，解码前需要构建状态图utils/mkgraph.sh   

解码会使用不同的解码参数生成多个文件，WER有微小的差异，最后找到最好的结果   

多数示例默认用sge集群 queue.pl   

单机 run.pl    

配置了 NFS 和免密登录，可以使用 ssh.pl 进行任务分发，需要在训练环境目录创建 .queue 文件夹没在其中创建 machines 文件，将要使用的机器名写在里面：   
$ cat  .queue/machines   
a01   
a02   
a03   

SLURM集群 slurm.pl   

local 包含用于处理当前示例数据的脚本、识别测试的脚本及除 GMM 训练外其他训练步骤的脚本   

steps 和 utils 是两个指向wsj下同名文件夹的链接   
steps 是各个训练阶段的子脚本。如：特征提取、单音素的 GMM 训练、三音素的 GMM 训练、神经网络模型训练、解码等   
utils 用于协助处理。如：任务管理、文件夹整理、临时文件删除、数据复制和验证等   
另外，还有一些特殊的顶层文件或文件夹。如：说话人识别、语种识别、图像识别、神经网络等 P43   

### 数据准备
训练 开发 测试 的用途和分布
不同质量,如清晰程度的数据用于不同阶段和场景
多机训练要确保数据路径在每个节点上都是可直接读写的
