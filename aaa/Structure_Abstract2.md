## 数据结构下
### 二叉搜索树
继承了二叉树的形式，同时也继承了向量的有序性   
有序性更集中体现在它的一个子集平衡二叉搜索树（BBST,balanced binary search tree）   
概述包括：定义、特点、规范   

二叉搜索树数据项之间,依照各自的关键码彼此区分 call-by-key ,需要关键码之间支持大小比较与、相等比对   
数据集合中的数据项统一地表示和实现为词条entry形式
```
template <typename K, typename V> struct Entry { //词条模板类
   K key; v value; //关键码、数值
   Entry( K k = K(), V v = V() ) : key(k)，value(v) {}; //默认构造函数
   Entry( Entry<K, V> const & e ) : key(e.key)， value(e.value) {}; //克隆
   //比较器、判等器(从此,不必严格区分词条及其对应的关键码)
   bool operator< ( Entry<K, V> const & e ) { return key < e.key; } //小于
   bool operator> ( Entry<K, V> const & e ) { return key > e.key; } //大于
   bool operator==( Entry<K, V> const & e ) { return key == e.key; } //等于
   bool operator!=( Entry<K, V> const & e ) { return key != e.key; } //不等
}
```
顺序性:任一节点均不小于左后代，不大于其右后代   
单调性: BST的中序遍历序列，必然单调非降   
|  |  |  | 4 |  |  |  |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
| | |↙| |↘| | |  
| |2| | | |6| |
|↙| |↘| |↙| |↘| 
|1| |3| |5| |7|
|↓|↓|↓|↓|↓|↓|↓|
|1|2|3|4|5|6|7|

这一性质，也是BST的充要条件//对树高 做数学归纳...   
符合这一性质的二叉树必然是BST   
模板类：
```
template <typename T> class BST : public BinTree<T> { //由BinTree派生
public: //以virtual1修饰 ,以便派生类重写
   virtual BinNodePosi(T) & search( const T & ); //查找
   virtual BinNodePosi(T) insert( const T & ); //插入
   virtual bool remove( const T & ); //删除
protected:
   BinNodePosi(T)  _hot; //命中上一级节点
   BinNodePosi(T) connect34( //3 + 4重构
      BinNodePosi(T), BinNodePosi(T), BinNodePosi(T),
      BinNodePosi(T), BinNodePosi(T), BinNodePosi(T), BinNodePosi(T));
   BinNodePosi(T) rotateAt( BinNodePosi(T) ): //旋转调整
```
查找：   
由于已经有序，而查找是从根节点开始，未命中的情况下每次能淘汰掉一边的子树（由于左子树一定小于根、右子树一定大于根），查找次数累计不过树的高度，查找过程参考中序遍历的结果可以发现，实际上类似于二分查找，以上面树为例，要查5，首先比根4大，所以左子树不用找了，然后比较右子树的根6，直接进入右子树的左子树；如果找不到，可以命中哨兵，哨兵数据为NULL   
减而治之:从根节点出发，逐步地缩小查找范围,直到发现目标(成功) , 或查找范围缩小至空树(失败),对照中序遍历序列可见,整个过程可视作是在仿效有序向量的二分查找   
```
template <typename T> BinNodePosi(T) & BST<T>::search(const T & e) //演示
{ return searchIn(_root, e,_hot = NULL ); } //从根节点启动查找,_hot直系上级节点

static BinNodePosi(T) & searchIn( //典型的尾递归，可改为迭代版
   BinNodePosi(T) & v, //当前(子)树根
   const T & e, //目标关键码
   BinNodePosi(T) & hot) //记忆热点
{
   if ( !v I (e == v->data) ) return v; //足以确定失败、成功,或者
   hot = v; //先记下当前(非空)节点,然后再...
   return searchIn( ( ( e < v->data ) ? v->lChild : v->rChild ), e, hot);
} //运行时间正比于返回节点v的深度，不超过树高O(h)
```
返回的引用值:   
成功时,指向一个关键码为e且真实存在的节点   
失败时,指向最后一次试图转向的空节点NULL   
失败时,不妨假想地将此空节点,转换为一个数值为e的哨兵节点   
如此，依然满足BST的充要条件;而且更重要地...这种方法可以将成功和失败的语义统一起来，hot指向上一级，命中正常或哨兵节点   
查询最坏情况，在BST退化成有序链表，且最小值作为根的情况下O(n)     

插入:   
先借助search(e)确定插入位置及方向,再将新节点作为叶子插入   
若e尚不存在，则: \_hot为新节 点的父亲 , v = search(e)为 \_hot对新孩子的引用(哨兵)   
```
template <typename T> BinNodePosi(T) BST<T>::insert( const T &e ) {
   BinNodePosi(T) & x = search( e ); //查找目标(留意_hot的设置)
   if ( !x){//既禁止雷同元素，故仅在查找失败时才实施插入操作
      x = new BinNode<T>( e, _hot ); //在x处创建新节点,以_hot为父亲
      _size++; updateHeightAbove( x ); //更新全树规模,更新x及其历代祖先的高度
   }
   return x; //无论e是否存在于原树中，至此总有x->data = e
} //验证:对于首个节点插入之类的边界情况，均可正确处置

```
删除：
```
template <typename T> bool BST<T>::remove( const T & e ) {
   BinNodePosi(T) & x = search( e ); //定位目标节点
   if ( !x ) return false; //确认目标存在(此时_hot为x的父亲)
   removeAt( x，_ hot); //分两大类情况实施删除,更新全树规模
   _size--; //更新全树规模
   updateHeightAbove(_ hot ); //更新_ hot及其历代祖先的高度
   return true;
}/删除成功与否，由返回值指示
```
当待删除目标只有一个子树为空时，删除后，用子树节点顶替它就好了   
```
template <typename T> static BinNodePosi(T)
removeAt( BinNodePosi(T) & x， BinNodePosi(T) & hot ) {
   BinNodePosi(T) W = x; //实际被摘除的节点,初值同x
   BinNodePosi(T) succ = NULL; //实际被删除节点的接替者
   if ( ! HasLchild( *x ) ) succ = x = x- > rChild; //左子树为空
   else if ( ! HasR)Child( Px ) ) succ = x = x->lChild; //右子树为空
   else { /* ...左右子树并存的情况，略微复杂些... */ }
   hot = w->parent; //记录实际被删除节点的父亲
   if ( succ ) succ->parent = hot; //将被删除节点的接替者与hot相联
   release( w->data ); release( W ); //释放被摘除节点
   return succ; //返回接替者
} //此类情况仅需O(1)时间
```
左右子树都存在的情况下，找到右子树中最小的，也就是右子树最左端的节点，与待删节点交换，然后再删除   
```
template <typename T> static BinNodePosi(T)
removeAt( BinNodePosi(T) & x，BinNodePosi(T) & hot ) {
   /* ..... */
   else { //若x的左、右子树并存，则
      W = W->succ(); swap( x->data, w->data ); //令*x与其后继*w互换数据
      BinNodePosi(T) u = w->parent; //原问题即转化为，摘除非二度的节点w
      (_u == x ? u->rChild : u->1Chi1d ) = succ = W -> rChild;
   }
   /* ..... */
}
```
删除方法中不包含循环，只有查找最左端节点时不超过树高h次，复杂度不过树高O(h)   
##### 平衡与等价
BST最坏情况下主要方法的复杂度都线性正比与树高O(h)，而暂时我们没有手段能控制树高，最坏情况下，树高可能等于节点数   
随机生成 ： 根据不同节点的插入顺序得到的个数，可能得到的树个数 n！个，平均复杂度O(logn)   
随机组成 ： 根据树的不同组成形式得到的个数，卡特兰数个catalan(n)，因为n!中有可能有不同的插入顺序生成同样结构的树的可能，平均复杂度O(n的平方根)   
所以，平均情况下，比通常的O(logn)要大一些，是O(sqrt(n))   
节点数目固定时,兄弟子树高度越接近平衡 , 全树也将倾向于更低   
由n个节点组成的二叉树,高度不低于1ogn - 恰为logn时 ,称作理想平衡。但实际中，很少会碰到完全二叉树(Complete Binary Tree
)和满树(Full Binary Tree)   
理想平衡出现概率极低、维护成本过高,故须适当地放松标准   
退一步海阔天空:高度渐进地不超过O(1ogn)，即可称作适度平衡   
适度平衡的BST，称作平衡二叉搜索树( BBST)   
BST的中序遍历有歧义性，不同的BST可能中序遍历结果一样，这些一样的BST，在BBST中称为相互等价的BST   
等价的BST，两个特点：   
上下可变:联接关系不尽相同 ,承袭关系可能颠倒(垂直方向)   
左右不乱:中序遍历序列完全一致，全局单调非降(水平方向)   
旋转zig(v)以顶点v为中心顺时针旋转，等价的BST，旋转前和旋转后(zigged)拓扑不同，但中序遍历相同   
zag(v)以顶点v为中心逆时针旋转,zagged   
包括AVL、红黑树在内的BBST都定义了某种适度平衡准则，有时树会超出准则，但可以通过一系列等价变换，变回来   
变换需要遵守两条规则：  
1.等价变换要局限在局部常数规模内，涉及变换的点是常数规模，计算时间也可以控制在常数规模   
2.重新恢复为BST的过程中，经过的变换次数不要太多，至多不能超过O(logn)   
AVL的删除操作刚达到及格线O(logn)，但插入可达O(1)；而红黑树(R/B)这两种操作都达到了常数   

#### AVL
理想平衡出现概率极低、维护理想平衡的成本过高,故须适当地放松标，树高至多O(logn)     
不平衡之后恢复到适度平衡的过程叫重平衡rebalance   
BBST核心技巧两条：一、如何选择适度标准；二、重平衡的算法   
BST的平衡因子：balFac(v) = height( 1c(v) ) - height ( rc(v) ）     
AVL树的适度标准：（发明者：G. Adelson-Velsky& E. Landis 1962) :[ ∀ v, | balFac(v) | ≤ 1 ]   
证明 height(AVL) = O(1ogn) 与 证明 n = Ω ( 2 ^ height(AVL) ) 等价   
高度为h的AVL树，至少包含S(h) = fib(h + 3) - 1个节点，斐波那契   
递推关系式：S(h)=1+S(h-1)+S(h-2)   
S(h)规模下限,1树根节点，-1、-2左右子树   
数学推导过程： S(h)+1=[S(h-1)+1]+[S(h-2)+1]   
T(h) = S(h)+1   
原式 => T(h) = T(h-1) + T(h-2)   
考察与斐波那契的项对应，从边界情况开始，只有一个节点：n=1, h=0, T(h)=S(h)+1=2实际树高＋1, 斐波那契第三项   
n=2, h=1, T(h)=S(h)+1=3, 斐波那契第四项    
归纳可见，是斐波那契后移3项fib(h + 3)   
斐波那契大致是[n = Ω (Φⁿ)](https://github.com/saaavsaaa/saaavsaaa.github.io/blob/master/aaa/Structure_Abstract.md)呈Φ的指数形式增长,写成对数形式h = O(logn)构成高度的上界，这刚好符合BBST适度平衡的要求，于是证明AVL符合BBST的要求，达到了适度平衡的标准   
接口：
```
#define Balanced(x) \ //理想平衡
( stature( (x).1Child ) == stature( (x).rChild ) )
#define BalFac(x) \ //平衡因子
( stature( (x).1Child ) - stature( (x).rChild ) )
#define AvlBalanced(x) \ //AVL平衡条件
((-2<BalFac(x))8&(BalFac(x)<2))

template <typename T> class AVL : public BST<T> { //由BST派生
public: // BST::search( )等接口，可直接沿用
   BinNodePosi(T) insert( const T & ); //插入重写
   bool remove( const T & ); //删除重写
};
```
删除节点造成失衡会引起直接前驱的失衡，但删除引起的失衡只会是因为删除了某个节点后继中比较短的一条边的节点，而树高和子树高是由较长的边决定的，但重平衡不容易   
插入造成失衡会造成所有前驱的失衡，因为它失衡是由于加长了最长的边，重平衡容易   

#### 插入
由于插入一个节点（v），它的直系前驱（p）不会失衡，所以距离插入节点最近的失衡节点，不会低于直系前驱的前驱（g）,同时可有多个失衡节点,最低者g不低于x祖父      
当v是g的“左子节点的左子节点”或“右子节点的右子节点”，就是p和v同侧时，只需要**单旋**，g经单旋调整后复衡，子树高度复原;更高祖先也必平衡,全树复衡   
当v是g“左的右”或“右的左”时，zig-zag或zag-zig，需要**双旋**，同样g重平衡后，g的所有前驱都适度平衡了   
```
template <typename T> BinNodePosi(T) AVL<T>::insert( const T & e ) {
   BinNodePosi(T) & x = search( e ); if ( x ) return x; //若目标尚不存在
   X = new BinNode<T>( e, _hot );_ size++; BinNodePosi(T) xx = x; //则创建x
//以下,从x的父亲出发逐层向上,依次检查各代祖先g
   for ( BinNodePosi(T) g = x->parent; g; g = g->parent )
   if ( !Av1Balanced( *g ) ) { //一旦发现g失衡,则通过调整恢复平衡
      FromParentTo( *g ) = rotateAt( tallerChild( tallerChild( g ) ) );
      break; //g复衡后 ，局部子树高度必然复原;其祖先亦必如此,故调整结束
   } else //否则(在依然平衡的祖先处) ,只需简单地
      updateHeight( g ); //更新其高度(平衡性虽不变,高度却可能改变)
   return xx; //返回新节点:至多只需一次调整
}
```
#### 删除
单旋：删除一般是由于删除了较短分支上的节点，最近的失衡节点可能是被删节点的直接前驱，由于删除后的重平衡可能导致删除节点所在子树的高度-1，所以重平衡可能导致该子树更高层次上的节点失衡（高层节点中删除节点的这一侧子树整体高度-1，而这一侧本身就是比较短的一侧），失衡不断向上传播，极端情况下可能达到logn次（习题解析【7-17】）   
双旋：zig-zag(与zag-zig对称)，与前面类似   
```
template <typename T> bool AVL<T>::remove( const T & e) {
   BinNodePosi(T) & x = search( e ); if ( !x ) return false; //若目标的确存在
   removeAt( x，_hot );_size--; //则在按BST规则删除之后，_hot及祖先均有可能失衡
//以下，从_hot出发逐层向上，依次检查各代祖先g
   for ( BinNodePosi(T) g = _ hot; g; g = g->parent ) {
      if ( ! Av1Balanced( *g ) ) //一旦发现g失衡,则通过调整恢复平衡
         g = FromParentTo( *g ) = rotateAt( tallerChild( tallerChild( g ) );
      updateHeight( g ); //并更新其高度
   } //可能需做过Ω(1ogn)次调整;无论是否做过调整,全树高度均可能下降
   return true; //删除成功
}
```
#### 3+4重构
单旋和双旋，逻辑上理解很容易，但实际中真的按逻辑去实现比较啰嗦，而无论怎么旋转，最后想要达到的效果都是中序遍历不变的最平衡形式，所以完全可以把插入、删除这两个逻辑过程中涉及的三个节点和这三个节点的子树共4棵，直接重组成结果的样式   
设g(x)为最低的失衡节点,考察祖孙三代:g~p~v，按中序遍历次序,将其重命名为:a<b<c，它们总共拥有互不相交的四棵(可能为空的)子树，按中序遍历次序,将其重命名为:T₀<T₁<T₂<T₃   
```
template <typename T> BinNodePosi(T) BST<T> : :connect34(
   BinNodePosi(T) a，BinNodePosi(T) b，BinNodePosi(T) c,
   BinNodePosi(T)T0，BinNodePosi(T)T1，BinNodePosi(T)T2，BinNodePosi(T)T3)
{
   a->1child = T0; if (T0)T0->parent = a;
   a->rChild = T1; if (T1)T1->parent = a; updateHeight(a);
   c->1Child = T2; if (T2)T2->parent = c;
   c->rChild = T3; if (T3)T3->parent = c; updateHeight(c);
   b->1Child = a; a->parent = b;
   b->rChild = c; c->parent = b; updateHeight(b);
   return b;//该子树新的根节点
}
```
统一调整:实现
```
template<typename T> BinNodePosi(T) BST<T>:: rotateAt( BinNodePosi(T) V ) {
   BinNodePosi(T) p = v->parent, g = p->parent; 
   if ( IsLChild( *p ) ) //zig
      if ( IsLChild( *v ) ) { //zig-zig
         p->parent = g->parent; //向上联接
         return connect34( v, p, g, v->1Child, V->rChild, p->rChild, g->rChild );
      } else { //zig-zag
         v->parent = g->parent; //向上联接
         return connect34( p, v, g, p->1Chi1d, v->1Child, v->rChild, g->rChild );
      }
   else ( /*.. zag-zig & zag-zag ..*/ }
}
```
AVL综合评价：   
优点：无论查找、插入或删除，最坏情况下的复杂度均为O(logn) O(n)的存储空间    
缺点：借助高度或平衡因子（人为引入平衡因子概念，伸展树就不需要）,为此需改造元素结构,或额外封装   
      实测复杂度与理论值尚有差距   
         插入/删除后的旋转，成本不菲   
         删除操作后,最多需旋转Ω(logn)次(Knuth :实际使用中，通常每5次左右会遇到一次，发生概率21%左右)   
         若需频繁进行插入/删除操作，未免得不偿失   
      插入和删除的复杂度严重不对等，单次动态调整后，全树拓扑结构的变化量可能高达Ω(logn)，红黑树插入删除就可以都控制在常数   

### 高级搜索树
#### 伸展树
AVL树需要处处小心，时时维护   
局部性 Locality: 刚被访问过的数据,极有可能很快地再次被访问。这一现象在信息处理过程中屡见不鲜   
BST :刚刚被访问过的节点，极有可能很快地再次被访问。下一将要访问的节点,极有可能就在刚被访问过节点的附近   
连续的m次查找(m >> n = |BST| )，采用AVL共需O(mlogn)时间
利用局部性,能否更快? 仿效链表，链表使用局部性的方法是，每访问一个节点就将该节点放到链表头，因为链表头部比尾部访问快很多   
对于BST，就是每访问一个节点，就通过旋转使该节点逐层上升，直至到达根节点，每访问一个就将它旋转到根   
但是如果只是这么做，极端情况下，树高就等于节点数，那么遍历所有节点的复杂度是1+2+...+n(因为叶子节点要旋转n次)，复杂度是Ω(n²)，均摊就是Ω(n)
节点v一旦被访问，随即转移至树根，一步一步往上爬，自下而上，逐层单旋 zig( v->parent ) 或 zag( V- >parent ) 直到v最终被推送至根   
旋转次数呈周期性的算术级数演变:每一周期累计Ω(n2), 分摊Ω(n)，远差与logn，还需要一些技巧上的调整，伸展策略已经完备了      

#### 双层伸展
技巧就是，对于双层单侧的形式(zig-zig或zag-zag)，g~p~v 不先旋转直接前驱 p，而是先旋转 p 的前驱 g，这样旋转结果就是对称形式的，比如zig-zig就会变成zag-zag，只有三层看不出来，如果是5层zig-zig形式的，例a-b-c-d-e，a为根，e是叶子，访问e
|  |  |  |  |  |  |  |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:| 
|1||||||a|
|2|||||b||
|3||||c|||
|4|||d||||
|5||e|||||

先旋转c，然后d，这时a-b-e-d-c，e是个转折
|  |  |  |  |  |  |  |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:| 
|1||||a|||
|2|||b|||| 
|3||e|||||
|4|||d||||
|5||||c|||

此时，e前驱的前驱是a，于是旋转a
|  |  |  |  |  |  |  |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:| 
|1||||b|||
||||↙||↘|| 
|2||e||||a| 
||||↘||||
|3||||d|||
|4|||||c||

再旋转d，e就成为树根了
|  |  |  |  |  |  |  |
|:-:|:-:|:-:|:-:|:-:|:-:|:-:| 
|1||e|||||
||||↘||||
|2||||b||| 
||||↙||↘||
|3||d||||a|
|4|||c||||

可以发现，树变矮了，而原本的方法，树高是不变得，而且，原树的高度越高，这种方法访问之后的高度变化会越大   
由于每两个节点会折叠一个到对称侧，对上例，从左到右，就是原左侧链只剩下了原来从底向上的第偶数个节点，奇数节点全都去了右侧，那么从倒数第3个节点开始，经过旋转每两层就会少一层。在不考虑倒数的3个节点的情况下，每经过一次从底到根，树高就会减少一半。   
折叠效果:一旦访问坏节点，对应路径的长度将随即减半   //含羞草：一旦遇到危险，遇到最坏情况就收缩起来   
最坏情况不致持续发生!   
单趟伸展操作，分摊O(logn)时间! /严格证明，详见习题[8-2]   
最后：   
在被访问节点 v 之上只有一层，无法双层伸展的情况下，此时必有parent(v) == root(T)，且每轮调整中，这种情况至多（在最后)出现一次视具体形态，做单次旋转:zig(r)或zag(r)，因此从渐近的意义而言并不会实质的影响整个调整过程的复杂度  
接口：   
```
template <typename T>
class splay : public BST<T> { //由BST派生
protected: BinNodePosi(T) splay( BinNodePosi(T) v );//将v伸展至根
public: //伸展树的查找也会引起整树的结构调整，故search()也需重写
   BinNodePosi(T) & search( const T & e );//查找重写
   BinNodePosi(T)insert(const T & e );//插入重写
   bool remove(const T & e );//删除重写
}
```
伸展算法：   
```
template <typename T> BinNodePosi(T) Splay<T>::splay( BinNodePosi(T) v ) {
   if ( ! v ) return NULL; BinNodePosi(T) p; BinNodePosi(T) g;//父亲、祖父
   while ( (p = v->parent) && (g = p->parent) ) { //自下而上，反复双层伸展
      BinNodePosi(T) gg = g->parent;//每轮之后，v都将以原曾祖父为父
      if ( IsLchild(* v ))
         if ( IsLChild(* p )){ /* zig-zig */ } else { /* zig-zag */ }
      else if ( IsRChild(* p) ){ /* zag-zag */ } else { /* zag-zig */ }
      if ( ! gg ) v->parent = NULL;//若无曾祖父gg，则v现即为树根;否则，gg此后应以v为左或右
      else ( g == gg->lc ) ? attachAsLChild(gg， v) : attachAsRChild(gg，v);//孩子
      updateHeight( g ); updateHeight( p ); updateHeight( v );
   }//双层伸展结束时，必有g == NULL，但p可能非空
   if ( p = v->parent ){/*若p果真是根，只需在额外单旋（至多一次)*/}
   v->parent = NULL: return v://迪展完成，v抵汰树相
}
```
四种情况(可参阅课后习题及课程附带的相关代码)：   
```
if(IsLChild(*v))
   if ( IsLChild( * p ) ) { //zIg-zIg
      attachAsLChild( g, p -> rc ); 
      attachAsLChild( p, v-> rc );
      attachAsRChild( p, g );
      attachAsRChild( v, p );
   } else { /* zIg-zAg */ }
else
   if(IsRChild(*p)){/* zAg-zAg */}
   else { /* zAg-zIg */ }
```
查找算法（如果未找到返回_hot，_hot应该就在根，后续的插入删除可以直接在根处操作）：   
```
template <typename T> BinNodePosi(T) & Splay<T>::search( const T & e )
//调用标准BST的内部接口定位目标节点
   BinNodePosi(T) p = searchIn(_ root, e, _hot = NULL );
//无论成功与否，最后被访问的节点都将伸展至根
   _root = splay( p ? p: _hot ); //成功、失败
//总是返回根节点
   return_ root;
}
```
插入：   
重写后的Splay::search()已集成了splay( )操作   
查找(失败)之后，_hot即是根节点   
具体的插入与普通的BST插入根节点一样   
删除：   
同样地, Splay: :search()查找(成功)之后，目标节点即是树根   
既如此, 何不随即就在树根附近完成目标节点的摘除...   
具体删除根可参考普通BST，比如找到右子树最小节点（右子树左侧链端点）   
综合评价：   
无需记录节点高度或平衡因子;编程实现简单易行一-优于AVL树   
分摊复杂度O(1ogn)--与AVL树相当   
局部性强、缓存命中率极高时(即k << n << m)，访问全局n个节点，一段时间内会只访问全局的一部分 k 个   
   效率甚至可以更高一自适应的O(1ogk)   
   任何连续的m次查找，都可在O(mlogk + nlogn) 时间内完成(aaa:操作次数远大于节点个数时，nlogn可以忽略)      
根据局部性原理，访问的数据会更多的在根节点附近命中，所以实际效率更高   
缺点：   
仍不能保证单次最坏情况的出现，因为树是不均衡的，最坏情况的调整代价很大   
不适用于对效率敏感的场合(任何一次的效率都要求很高的情况不适用),如手术室里器械相关的就不能合适   
复杂度的分析稍嫌复杂---这里只是简单分析，具体证明习题【8-2】   

### B树
严格来说B树并不是二分查找树，但逻辑上依然等效于BST，所以也归为高级搜索树，它可用于高效的I/O   
640K ought to be enough for anybody. - Bill. Gates，1981（在虚拟内存、内存交换和内存分页这三者结合下，运行一个程序，“必须”的内存很少。CPU只需要执行当前的指令，极限情况下，内存也只需要加载一页。其他的只在用到对应的数据和指令时，从硬盘交换到内存。以4k内存一页的大小，640K内存能放下足足160页，理论上足以运行任何规模的程序）   
RAM :存储器?不就是无限可数个寄存器吗?   
Turing:存储器?不就是无限长的纸带吗?   
实际中不可能有无限个，无限是一种过于理想的假设   
但事实上,系统存储容量的增长速度 << 应用问题规模的增长速度   
典型的 数据库规模/内存容量:   
   1980   :   10MB / 1MB = 10   
   2000   :   1TB / 1GB = 1000   
今天典型的数据集须以TB为单位度量:    
   345 TB ^ Global climate   
   300 TB ^ Nuclear   
   250 TB ^ Turbulent combustion   
   50 TB  ^ Parkinson's disease   
   10 TB  ^ Protein folding   
亦即，相对而言，内存容量是在不断减小!    
而内存不能做大点的原因是，容量越大，访问速度越慢，不得不在存储器的容量与它的访问速度之间做一取舍折中   
使用高速缓存解决容量和速度的矛盾，将存储分为多层，越向下层越大   
事实1 :不同容量的存储器,访问速度差异悬殊   
以磁盘与内存为例: ms量级(10<sup>-3</sup>)/ns量级(10<sup>-9</sup>) > 10<sup>5</sup>,保守估计至少也是5个数量级     
从前面学过的封底估算可知，若一次内存访问需要一秒，则一次外存访问就相当于一天，相当于从眼前那一只粉笔和坐火车跑半个中国买只粉笔回来   
为避免 1 次外存访问,我们宁愿访问内存10次、100次，甚至...   
多数存储系统，都是分级（CPU高速缓存、内存RAM、DISK磁盘、DISK ARRAY磁盘阵列等）组织的一一Caching，最常用的数据尽可能放在更高层、更小的存储器中，实在找不到，才向更低层、更大的存储器索取   
上下级存储之间访问速度差异巨大，下级相对于上级就是外存，需要尽量减少对外存的访问次数   
事实2 :从磁盘中读写1B，与读写 1KB 几乎一样快，就像坐火车采购一只和一盒差不多     
批量式访问:以页( page )或块( block )为单位,使用缓冲区//<stdio.h>...   
C 语言缓冲区接口，可以自定义缓冲区一次读取大小
```
#define BUFSIZ 512 //缓冲区默认容量
int setvbuf( //定制缓冲区
   FILE* fp, //流
   char* buf, //缓冲区
   int _Mode, // _IOFBF | _IOLBF | _IONBF 工作模式
   size_ t size); //缓冲区容量
int fflush(FILE* fp); //强制清空缓冲区
```
或者不读取，要读取就一次读取若干KB；坐火车要不就不买，买就买很多   

B树特点：1.每个节点不一定又几个分支；2.所有叶子节点高度一样（从这个角度看不失为一个理想平衡的搜索树）；3.相较于同样节点树的二叉树更宽、更矮；   
平衡的多路(multi -way)搜索树，实际与BST二路搜索树是等价的   
可以将B树节点看做一个超级节点     
经适当合并,得超级节点（每个超级节点含有多个关键码）   
   每2代合并: 4路    
   每3代合并:8路   
   每d代合并:m = 2<sup>d</sup>路，m - 1个关键码   
逻辑上与BBST完全等价，使用B树的原因主要是多级存储系统中使用B树，可针对外部查找,大大减少I/O次数   

对于AVL，若有n = 1G个记录...最坏情况下每次查找需要 1og(2, 10<sup>9</sup>) = 30 次I/O操作，每次只读出一个关键码,得不偿失   
B树充分利用外存对批量访问的高效支持，将此特点转化为优点，每下降一层,都以超级节点为单位，读入一组关键码

具体一组多大视磁盘的数据块大小而定（超级节点大小取决于磁盘等外存本身所设定的数据缓冲页面的大小，数据缓冲页一般若干KB，如果每个关键码4个字节，那很超级节点自然取200 ~ 300），m = #keys / pg。比如，目前多数数据库系统采用m=200 ~ 300    
回到上例，若有n = 1G个记录，若取m= 256，则最坏情况，查找只需 log(256, 10^9) <= 4 次I/O
虽然4和30都是常数，渐近意义下差不多，但常数的单位到达10的5、6次方时，就需要考虑了，比如一年和一秒都时常数   

定义m 阶B树，即 m 路 平衡搜索树(m ≥ 2)   
   外部节点的深度统一相等（哨兵节点，不包含关键码，B树和其它普通树不同，计算树的高度时需要把外部节点考虑进去）   
   所有叶节点的深度统一相等   

阶数给除了上限和下限，内部节点各有：   
   不超过 m-1 个关键码:  K₁ < K₂ <...< Kn   
   不超过 m 个分支: A₀, A₁, A₂,..., An   
下限：内部节点的分支数n + 1也不能太少，具体地    
   树根:2 ≤ n+1   
   其余:m/2 ≤ n+ 1   

既然如此我们也用超级节点所拥有分支数的下限、上限来命名 B 树：(m/2, m)树，（向上取整）   
   如5阶(也就是最多5个分支，4个关键码):(3,5)树；6阶:(3,6)树；7阶:(4,7)树...    
   其中(2,4)树与红黑树关系密切   

BTNode:   
一个超级节点可以用两个向量实现，一个存放n个关键码，另一个存放n+1个分支引用   
```
template <typename T> struct BTNode { //B-树节点
  BTNodePosi(T) parent; //父
  Vector<T> key; //数值向量
  Vector< BTNodePosi(T) > child; //孩子向量(其长度总比key多一 )
  BTNode() { parent = NULL; child. insert( 0, NULL ); }
  BTNode( T e, BTNodePosi(T) 1c = NULL, BTNodePosi(T) rc = NULL )
    parent = NULL; //作为根节点，而且初始时
    key.insert( 0, e ); //仅一个关键码，以及
    child.insert( 0, lc ); child.insert( 1, rc ); //两个孩子
    if ( 1c ) lc->parent = this; if ( rc ) rc->parent = this ;
}
```
BTree:   
```
#define BTNodePosi(T) BTNode<T>* //B-树节点位置
template <typename T> class BTree { //B-树
protected :
  int _size; int _order; BTNodePosi(T) _root; //关键码总数、 阶次、根
  BTNodePosi(T) _hot; //search( )最后访问的非空节点位置
  void solveOverflow( BTNodePosi(T) ); //因插入而上溢后的分裂处理
  void solveUnderflow( BTNodePosi(T) ); //因删除而下溢后的合井处理
public:
  BTNodePosi(T) search(const T & e); //查找:
  bool insert(const T & e); //插入
  bool remove(const T & e) //删除
}
```
查找(逐层深入，减而治之)：   
外部节点可能不存在，也可能是更低一层的外部存储器   
查找过程就是IO操作和向量查找交替的过程   
如果查找失败，必然失败于外部节点   
```
template <typename T> BTNodePosi(T) BTree<T>::search( const T & e) {
  BTNodePosi(T) v = _ root; _hot = NULL; //从根节点出发
  while(v) { //逐层查找
    Rank r = v->key.search(e); //在当前节点对应的向量中顺序查找
    if ( 0 <= r && e == v->key[r]) return v; //若成功，则返回;否则...
    _hot = v; v = v->child[r + 1]; //沿引用转至对应的下层子树，并载入其根I/O
  } //若因!v而退出，则意味着抵达外部节点
  return NULL; //失败
}
```
向量的查找用的是顺序查找，在此场景下，由于内外存访问的巨大差异，二分查找的未必更好，甚至可能更差，一个超级节点规模是几百，试验表明，这个规模下顺序可能比二分更好   
##### B树可能的最大高度：   
树根为第0层，外部节点第h层   
含 N 个关键码的 m 阶B树，为了让树高度最大，内部节点应尽可能“瘦”,各层节点数依次为   
  n₀=1，n₁=2, n₂=2x(m/2), ... ,nₖ = 2 x (m/2)<sup>k-1</sup>   
N个内部节点，N+1个外部节点   
N种成功可能，N+1种失败可能   
考查外部节点所在层   
  N+1 = nₕ ≥ 2 x (m/2)<sup>h-1</sup>  (nₕ的确界和下界) 
  h ≤ 1 + 1og<sub>m/2</sub>(N + 1)/2 = O(logₘN)
1ogₘN中的底数可以视为常数，与BST的性能渐近同阶，B树的意义并不在于降低搜索的渐近时间复杂度，而是更加关注于常系数意义下的优化   
相对于BBST :   
  log<sub>m/2</sub>(N/2) / 1og₂N = 1/(1og₂m - 1)   
若取 m = 256 树高 (I/O次数) 约降低至1/7    
##### B树高度的下界：   
类似的   
含 N 个关键码的 m 阶B树，为了让树高度最小，内部节点应尽可能"胖", 分支数不得超过m   
各层节点数依次为:   
  n₀=1, n₁=m, n₂=m², n₃ = m³, ... , n<sub>h-1</sub>=m<sup>h-1</sup> , nₕ = m<sup>h</sup>   
考查外部节点]所在层:   
  N+1 = nₕ ≤ m<sup>h</sup>   
  h ≥ logₘ(N + 1) = Ω(logₘN)   
相对于BBST: (logₘN - 1) / log₂N = logₘ2 - log<sub>N</sub>2 ≈ 1/log₂m     
若取 m = 256 树高 (I/O次数) 约降低至1/8     

综上，关键码数量固定时，B树高度的上下浮动范围是非常有限的，几乎可以忽略树高的变化   
##### 插入   
```
template <typename T>
  bool BTree<T>::insert( const T & e ) {
  BTNodePosi(T) v = search(e); 
  if(V) return false; //确认e不存在
  Rank r = _hot->key.search( e ); //在节点_hot中确定插入位置
  _hot->key.insert( r + 1, e]); //将新关键码插至对应的位置
  _hot->child.insert( r + 2, NULL ); //创建一个空子树指针
  _size++; solveOverflow( hot ); //如发生上溢，需做分裂
  return true; //插入成功
}
```
可以约定在_hot(key.search向量查找方法，返回不大于e的最大关键码)右侧引用插入   
另外，r+2(可以约定给新关键码增加右侧分支引用[指向下级节点的])处插入空节点的操作也可以用直接在向量尾部加，因为e不存在，那么一定命中了外部节点   
插入节点可能导致上溢出(超出B树阶次的规定)，需要进行分裂   

发生了上溢的超级节点应该刚好有m个关键码、m+1个分支(多了一个)，设上溢节点中的关键码依次为：k₀, k₁, k₂,..., k<sub>m-1</sub>   
取中位数s= m/」, 以关键码 kₛ 为界划分为 【k₀, k₁, k₂,..., k<sub>s-1</sub> 】【 kₛ 】【 k<sub>s+1</sub>,..., k<sub>m-1</sub> 】   
关键码 kₛ 上升一层,并分裂spiit:以所得的两个节点作为左、右孩子   
 kₛ 上升可能会导致上一级的超级节点上溢，于是继续向上，直至根节点，根节点上溢是唯一一种导致B树增高的情况，而根节点上溢结束，新的根就只有一个关键码和两个分支，所以在定义B树时对根有一个例外的规定，根节点不用必须遵守阶次要求，分裂本身是常数操作，而分裂次数最坏情况等于树高，所以插入复杂度线性正比于树高      
上溢概率十分低，严格证明参考习题解析   

##### 删除
```
template <typename T>
bool BTree<T> ::remove( const T & e ) {
  BTNodePosi(T) v = search( e );
  if ( ! v ) return false; //确认e存在
  Rank r = v->key.search(e); //确定e在v中的秩
  if ( v->child[0] ) { //若v非叶子，则
    BTNodePosi(T) u = v->child[r + 1]; //在右子树中一直向左，即可
    while ( u->child[0] ) u = u->child[0]; //找到e的后继(必属于某叶节点)
    v->key[r] = u->key[0]; v = u; r = 0; //并与之交换位置
  }//至此，v必然位于最底层，且其中第r个关键码就是待删除者
  v->key.remove(r);v->child.remove(r+1);_size--;//同样这里可以不是r+1，可以是任意一个
  solveUnderflow( v ); return true;//如有必要，需做旋转或合并
}
```
节点v下溢时，必恰好包含: [m/2]-2 个关键码 和 [m/2]-1 个分支    
下溢时，首先左顾右盼，看看同一个前驱里紧邻的节点中有没有可以借出一个关键码的，如果有则旋转。这里并不直接借关键码过来，因为要保证B树中序遍历的顺序性，将前驱关键码借过来，并将同级的待借关键码填到前驱的位置上   
L和R或者不存在，或者所含的关键码均不足[m/2]个。注意，L和R仍必有其一，且恰含_[m/2]-1 个关键码（不妨以为例)。那发生下溢的当前超级节点和(L或R)的关键码加起来恰好是 m-2 个关键码、m-1 个分支。此时，可以将它们合并，为了保证中序的顺序性，将它们的直接前驱作为交接点，连接这两个超级节点。这样，就刚好m-1 个关键码、m 个分支。此时，直接前驱超级节点本身也可能发生下溢，解决方法同上。次数最多树高，累计不过O(h)    
B树内存和外存操作交替进行，有多少次内存操作就有多少次外存操作，为了保证高效率，应该保证内存与外存操作的效率大致相当。B树为了做到这一点调整了形态，降低树高、加大节点成超级节点，前面的AVL等BST不能。   

#### 红黑树
BST基本的足够快的动态自平衡   
之前学到的数据结构都是ephemeral的，只能看到当前状态，历史状态都丢弃了   
Persistent structure:支持对历史版本的访问   
T.search((ver,key); T.insert(ver,key); T.remove(ver,key)   
蛮力实现∶每个版本独立保存;各版本入口自成一个搜索结构，单次操作时间  O(logh + logn)，累计 O(h * n)  空间，空间复杂度不可接受   
可以利用相邻版本间的关联性，将复杂度控制在O(n + h\*logn)内   
对于相邻两个历史快照，后者都是在前者的基础上做过相对而言少量的更新而得的   
实现方法得当完全可以将相邻版本之间的差异量控制在logn的范围，具体实现的数据结构可以看《计算几何》课程   
还可以进一步提高，总体O(n + h),单版本O(1)，为此，就BBST树形结构的拓扑而言，相邻版本之间的差异不能超过O(1)   
所谓的拓扑结构差异无非是来自自调整过程中的旋转操作，每一次局部的旋转都意味着在结构上引入常数的差异。因此反过来，如果需要保证前后版本在拓扑结构上的差异不超过常数，也就是前一版本到后一版本过程中所执行的旋转操作不得超过常数次。AVL的插入可以但删除就无法满足，如果想要做到这一点，任何一次动态操作（插入删除等）引发的结构变化量都需要不致超过O(1)，红黑树可以满足。   

红黑树曾经的命名:   
1972，R. Bayer，“"symmetric binary B-tree"   
1978，L. Guibas & R. Sedgewick，“red-black tree”   
1982，H. olivie，" half-balanced binary search tree"   

由红、黑两类节点组成的BST //亦可给边染色(统一增设外部节点NULL，使之成为真二叉树)   
(1）树根:必为黑色   
(2）外部节点:均为黑色（实际并不存在）   
(3）其余节点∶若为红，则只能有黑孩子/红之子、之父必黑(不能有两个项链的红节点)   
(4)外部节点到根:途中黑节点数目相等 //黑深度   

之前提过红黑树和(2,4)B树有关，通过树形结构的一种等价拓扑变换--提升变换，可以发现红黑树的定义使它提升变换之后刚好是一颗4阶B树   
此处提升变换是黑节点不动，所有红节点都提升到其直接前驱的黑节点同级，并与该黑节点组成一个超级节点，可以发现，没有红后继的超级节点是一个关键码，有红后继的最多可能会有两个，也就是 3 个关键码，刚好是一个 4 阶B树，高度就是黑高度，因为所有分支的黑节点个数相同   
提升各红节点，使之与其(黑）父亲等高——于是每棵红黑树，都对应于一棵(2，4)-树将黑方点与其红孩子视作（关键码并合并为)超级节点，无非四种组合，分别对应于4阶B-树的一类内部节点 //反过来呢?   
由等价牲，既然B-树是平衡的，红黑树自然也应是 //更严谨地...   
定理:包含n介内部节点的红黑树 T,高度h = o(logn)。log(n+1) ≤ h ≤ 2 * log(n+1)，第一个不等号BST都天然满足，主要是看 h ≤ 2 * log(n+1)  
红黑树的高度是用黑高度度量的，红节点不能相连，那任何分支上红节点的数量都不超过分支长度的一半，黑节点数量至少是长度的一半，实际高度不超过黑高度的两倍   
若:T高度为h，黑高度为H，则:h = R+ H ≤ 2H，若T所对应的B树为T<sub>B</sub>，则 H 即是T<sub>B</sub>的高度   
T<sub>B</sub>的每个节点，包含且仅包含T的一个黑节点   
由于等价，我们只需去度量红黑树对应的那棵B树的高度即可，于是，H ≤ log<sub>[4/2]</sub>   
```
template <typename T> class RedBlack : public BST<T>{//红黑树
public: //BST::search()等其余接口可直接沿用
  BinNodePosi(T) insert(const T & e );//插入(重写)
  bool remove(const T & e );//删除（重写)
protected:void solveDoubleRed(BinNodePosi(T) x);//双红修正
  void solveDoubleBlack(BinNodePosi(T) x);//双黑修正
  int updateHeight(BinNodePosi(T) x);//更新节点x的高度
};

template <typename T> int RedBlack<T>: :updateHeight( BinNodePosi(T) x )
  x->height = max( stature( x->1c ), stature( x->rc ) );
  if (IsBlack( x ) ) x->height++; return x->height;//只计黑节点
}
```
##### 插入
对红黑树的动态操作需要参照对应的B树，并不是说按照B树的方法实际进行，只是逻辑理解方面   

现拟插入关键码e //不妨设T中本不含e   
按BST的常规算法，插入之 //= insert(e)必为末端节点   
不妨设x的父亲p = x->parent存在 //否则，即平凡的首次插入   
将x染红(除非它是根)(如果不染红，各分支长度就不好控制了) //×->color = isRoot(x)? B : R   
定义中 1＋2＋4依然满足﹔但3不见得，因为插入节点的直接前驱可能是红色，这就造成两个红色紧邻，称为双红缺陷   
双红double-red //p->color == x->color == R   
考查:x的祖父 g = p->parent //g != null && g->color == B 因为根必然为黑，所以如果插入导致双红缺陷则g必然存在且是黑色   
p的兄弟 u = p == g->lc? g->rc : g->lc   //即x的叔父   
```
template <typename T> BinNodePosi(T) RedBlack<T>::insert( const T & e ) {
//确认目标节点不存在（留意对_hot的设置)
  BinNodePosi(T) & x = search( e ); if ( × ) return x;
//创建红节点x，以_hot为父，黑高度-1
 x = new BinNode<T>( e,_hot，NULL，NULL, -1 ); _size++;
//如有必要，需做双红修正
  solveDoub1eRed( x );
//返回插入的节点
  return x ? × : _hot->parent;
} //无论原树中是否存有e，返回时总有x->data == e
```
提升变换：将指向红色节点的边收缩起来   
对于产生了双红缺陷的情况，三级节点一共有四种组合，当叔父节点是黑的，只需要考虑x、p、g的 4 种组合形式，这里只考虑zig-zig、zig-zag，另两种对称   
此时:x、p、g的四个孩子(可能是外部节点)全为黑，且(黑)高度相同，x、p、g聚成一个超级节点符合4阶B树的规则   
对应的B树并没有结构上的问题，只是颜色不对，只需要对x、p、g重新染色，使p为黑，另外两个红，参照AVL做3+4重构，直接构建正确的结构和染色即可   
从B树的角度，如何理解这一情况:   
1．调整前之所以非法，是因为在某个三叉节点中插入红关键码，使得原关键码不再居中//RRB或BRR，出现相邻的红关键码   
2．调整之后的效果相当于 //B树的拓扑结构不变，但在新的四叉节点中，三个关键码的颜色改为RBR   

当叔父 u 节点为红，提升变换后，x、p、g、u成为了一个超级节点，超过了4阶B树的规定   
此时的双红缺陷在B树中，等效于超级节点发生上溢，于是进行分裂，找到居中节点g，将它提到上一级，然后分裂成两个节点x、p和u，这个分裂等效于红黑树中g由黑转红、p和u由红转黑(每个超级节点有一个黑色关键码)，事实上不需要结构变化，可以画图（先转B树，分裂，再转红黑树）理解。g提升后，上一级可能继续发生双红缺陷，双红缺陷的情况无非这两种，而且继续向上传播最高不过树根，所以拓扑结构变化(3+4重构)最多常数(因为发生拓扑结构变化就不需要分裂，不会向上传播，其中只有分裂向上传播，就不会有拓扑结构变化)，重染色最多logn次         

双红修正(复杂度):   
重构(3+4)、染色均属常数时间的局部操作，故只需统计其总次数   
红黑树的每一次插入操作都可在O(logn)时间内完成，其中至多做:   
1.O(logn)次节点染色   
2.一次“3+4”重构   
|情况|旋转次数|染色次数|此后|
|:-:|:-:|:-:|:-:|
|u为黑|1~2|2|调整随即完成|
|u为红|0|3|可能再次双红，但必上升两层|

如此关注拓扑结构的变化，是的这类操作对于持久化结构而言是至关重要的   

##### 删除
删除操作的可能性比插入要多，同样借助提升变换为B树进行理解具体进行的操作方法，需要注意结构变化需要控制在不高于常数   
首先按照BST常规算法，执行:   
```
r = removeAt(×,_hot )
```

如果返回的是r（r有可能是并不存在的外部节点），则x原来的位置由孩子r接替 //另一孩子记作w(即黑的NULL)   
条件1和依然满足但3和4不见得 //在原树中，考查x与r    
http://dsa.cs.tsinghua.edu.cn/~deng/ds/src_link/bst/bst_removeat.h.htm   
若x或r二者之一为红，则3和4很容易满足，如果：x红r黑 交换后 删除x即可([示例代码:](http//dsa.cs.tsinghua.edu.cn/~deng/ds/src_link/redblack/redblack_remove.h.htm)只检查红，染黑，如果出现双黑则solveDoubleBlack)；x黑r红，r替换了x后，这个位置变红了，这个分支就短了一个黑节点，这时只需将r染黑删除遂告完成!   

若x与r均黑double-black，摘除x并代之以r后全树黑深度不再统一，原B-树中x所属节点下溢   
在新树中，考查r的父亲p = r->parent 、/亦即原树中x的父亲   
r的兄弟s(sibling) = r == p->lc ? p->rc : p->lc   
分 4 种情况:http://dsa.cs.tsinghua.edu.cn/~deng/ds/src_link/redblack/redblack_solvedoubleblack.h.htm    

BB-1:s为黑，且至少有一个红孩子t。   3+4重构:t、s、p重命名为a、b、c；r保持黑;a和c染黑;b继承p的原色，如此，红黑树性质在全局得以恢复——删除完成!//zig-zag等类似   
在对应的B-树中，以上操作等效于通过关键码的旋转，消除超级节点的下溢（删除后下溢的这个节点关键码为0个）。B树向同级借一个节点消除下溢   

BB-2R:s为黑，且两个孩子均为黑;p为红，r保持黑;s转红;p转黑在对应的B-树中，等效于下溢节点与兄弟合并，p下降变黑连接s合并成新超级节点，同时因为p原为红色，所以原超级节点必有且仅有一个黑色节点，不会继续下溢。相当于，以p为中心将两个子节点合并成一个新超级节点   

BB-2B:s为黑，且两个孩子均为黑;p为黑。由于p为黑，下溢会继续，有可能持续到根，极端可能logn次，但对红黑树来说实际上sp的合并只是进行了重染色，一旦发生3+4重构，就一定会停止，否则持续到根的都是重染色，所以拓扑结构的变化依然不超过常数。相当于，对两个分支做平衡，使两个分支黑高度相同，并将下溢向上传导   

**BB-3?** :s为红（其孩子均为黑）。zag(p)或zig(p);红s转黑，黑 p 转红黑高度依然异常，但 r 有了一个新的黑兄弟 s' 故转化为前述情况，而且既然p已转红，接下来绝不会是情况BB-2B而只能是BB-1或BB-2R。于是，再经一轮调整之后红黑树性质必然全局恢复。对比原图可以发现s'的黑高度应该比原来的x高，因为S原本是红的，所以旋转之后，s比r高，这里应该就是旋转之后还不平衡的原因   
```
      P_b                      S_b
  S_r        X_b          0           P_r
0    1(s')   2(R_b)               1(s')   X_b
                                         2(R_b)
```

|情况|旋转次数|染色次数|此后|
|:--|:-:|:-:|:--|
|(1)黑s有红子t|1~2|3|调整随即完成|
|(2R)黑s无红子,p红|0|2|调整随即完成|
|(2B)黑s无红子p黑|0|1|必然再次双黑，但将上升一层|
|(3）红s|1|2|转为(1)或(2R)|

红黑树的每一删除操作都可在O(1ogn)时间内完成。其中，至多做:   
1.O(1ogn)次重染色   
2.一次“3+4”重构   
3.一次单旋   

## 词典
向量 vector：寻秩访问 rank；列表 list：寻位置访问 position；二叉搜索树 BST：寻关键码访问 key   
散列 hashing：寻值访问 value   
对值进行映射，以方便访问，比如很长的电话号记不住，可以借助数字键对应的英文，例如：111 -> ABC(只是个例子，不要纠结111)   
类似电话这种，实际使用了的号码远小于可使用的号码（n位0-9 : 10ⁿ），所以如果使用向量，寻号码的位置访问，意味着向量长度需要达到10ⁿ，空间复杂度过高，没用上的空间过多   
桶 bucket:直接存放或间接指向一个词条   
桶数组 bucket array 或称 散列表 hash table，容量为 M : N < M << R，N和M应该同阶   
空间 = O(N + M) = O(N)   
定址/杂凑/散列:   
根据词条的key(未必可比较)直接确定散列表入口   
散列函数: hash() : hash(key) -> entry   
散列函数设计得当可以将期望expected 控制在O(1) 常数   
例如25K个电话号码可以对90001取模，这个数相对N要足够大，但数量级要和N同阶，空间效率取决于装填因子(load factor) λ = N/M   

hash冲突：key1 ≠ key2，但hash( key1 ) 可能 = hash( key2 )  例如： 51531876 和 62782081 %90001 都等于 51304，这种冲突是很难彻底杜绝的，因为这是将一个大范围数据 R 映射到一个小范围中，但是策略和方法（散列函数和冲突发生后的排解）得当可以将冲突概率控制在足够低的水平   

虽然冲突不可避免，不能真的单射，但往往可以做到近似的单射    
两项基本狂务：   
本节 ：精心设计散列表及散列函数，以尽可能降低冲突的概率;   
下节：制定可行的预案   

评价标准与设计原则，什么样的散列函数hash()更好②：   
1)确定determinism:同一关键码总是被映射至同一地址   
2）快速efficiency：expected-O(1)   
3）满射surjection：尽可能充分地覆盖整个散列空间   
4）均匀uniformity：关键码映射到散列表各位置的概率尽量接近，可有效避免聚集clustering现象   

除余法：hash( key) = key % M，前例中，为何选 M=90001? 若取 M=2^k,其效果相当于截取key的最后k 位( bit)，前面的n - k位对地址没有影响   
M - 1 = 0 0 0 ... 0 | 1 1 1 ...1     
key % M = key & (M - 1)   
推论∶发生冲突 iff 最后k位相同 //发生冲突的概率大   
2^k去摸计算虽然快，但冲突的概率相对也更大，对 M 同余的所有数会被映射到同一个位置。最大公约数为1的可能冲突概率最小，数据在映射范围内分布的也最均匀，所以最好选择质数，它的因数最少      
实际中处理数据多有一种局部性 locality，其中一种典型是以某一步长 step 在序列中单调分布(程序中while等循环处理的)，S步长、M序列长度、G最大公因子： gcd (S , M) = G，序列如果可以分布在整个空间，就具备均匀性，借助数论的知识可知，遍布在整个空间当且仅当最大公因子是1   
不同种类的蝉，生命周期大多是素数，如13、17年，对应散列表，比如散列表长度13。蝉有很多天敌，它的天敌有不同的生命周期，类似步长S，每过S年，天敌更新一代，蝉只能希望同一年不会遇到更多的天敌，反过来天敌分布的更均匀，所以与天敌的生命周期最大公约数为1最好   

MAD法：对除余法的改进，其缺陷：   
1 )不动点:无论表长 M 取值如何，总有hash(0) = 0   
2) 零阶均匀: \[0，R)的关键码，平均分配至N个桶;但相邻关键码的散列地址也必相邻   
一阶均匀:邻近的关键码，散列地址不再邻近，更高阶均匀性做法：   
MAD （multiply-add-divide  
a相当于step，b相当于offset   
取 M 为素数, a>0, b> 0, a % M ≠ 0   
hash( key ) = (a × key + b) % M   
之后相邻关键码映射后相距a   
当然特定场合下，未必需要高阶的均匀性，比如几何计算(Geometric computing)，从高维空间压缩到低维空间，可能需要临近的关键码被映射到临近的位置，称为Locality-Sensitie Hashing局部敏感哈希    
通常hash是从大空间映射到小空间，但hash的准则很灵活，但反过来也大有用处，比如密码学cryptology   

更多散列函数：
数字分析 selecting digits 抽取key中的某几位，构成地址，比如，取十进制表示的奇数位 hash(1 2 3 4 5 6 7 8 9) = 1 3 5 7 9，分组必须是确定的，因为要符合确定性，但均匀性不好，并不是所有的数位都对最终的散列地址有贡献   
通过平方取中法改进：
平方取中 mid-square 取key²的中间若干位，构成地址   
hash( 123 ) = 512 //保留 key平方 = 123² = 1[512]9 的中间3位   
hash( 1234567 ) = 556 // 1234567² = 15241[556]77489   
因为根据乘法运算，靠中间位置的数会受到更多的参与运算的各个数位上的数的影响，而比如乘法的最低位只受最低位数的影响，最高数位同样几乎只受高数位的影响   
取居中的数位可以使原关键码的各数位对最终地址的影响尽量接近   

沂叠法fo1ding : 将key分割成等宽的若干段，取其总和作为地址   
hash( 123456789 ) = 1368 //123+456 + 789，自左向右   
hash( 123456789) = 1566 //123 +654 + 789，往复折返（变种）   
位异或法xOR : 将key分割成等宽的二进制段，经异或运算得到地址   
hash( 110011011<sub>b</sub>） = 110<sub>b</sub> //110 ^ 011 ^ 011，自左向右   
hash( 110011011<sub>b</sub>) = 011<sub>b</sub> // 110 ^ 110 ^ 011，往复折返   
此类方法林林种种，总之，越是随机，越是没有规律，就越好   

系统的随机数发生器实际上并不是真的随机，把范围内的数编成一个貌似随机实则确定的序列，返回某个秩对应的值，最常见的秩比如系统当前时间   
这与散列函数十分相似，可以借助它来实现散列函数   
确定＋高效 + 满射＋均匀这4条标准同时也是伪随机数发生器的重要评判标准   
可以把难题雄给伪随机数发生器，但是...   
(伪）随机数发生器的实现，因具体平台不同历史版本而异，创建的散列表可移植性差——故需慎用此法!   

关键码不一定都是整数，数值型的比较容易转成整数再转为桶地址，此处讨论字符串型：   
多项式法：   
hash( s = X₀ x₁ ... x<sub>n-1</sub> ) = x₀a<sup>n-1</sup> +x₁a<sup>n-2</sup> + .. +x<sub>n-2</sub>a¹ + x<sub>n-1</sub>   
将字符串的每一位转换成特定的整数，再将它们当做一个多项式的系数，选择特定的 a 计算出多项式的值作为散列地址，这个一元n次多项式可以在O(n)时间内求解   
可以用一下方法避免乘法运算，对英文尤其有效：   
```
static size_t hashCode(char s[] ) { //近似多项式，但更快捷
  int h = 0;
  for ( size_t n = strlen(s), i = 0; i < n; i++)
    { h = (h << 5) | (h >> 27); h += (int) s[i]; }
  return ( size_t ) h;
} //有必要如此复杂吗?
```
如果直接将英文字符与特定数字对应起来，冲突概率会非常大，因为两个字符串（两句话）对应整数的累加值很容易相等，就算不相等也很容易通过一些辅助字符修正成相等   

冲突不可避免，如何排解冲突，做好遇到冲突的预案
多槽位法 multiple slots：桶单元细分成若干槽位slot，存放（与同一单元）冲突的词条，只要槽位教目不多（常数个），依然可以保证o(1)的时间效率，但是槽位数都是事先固定，但事先无法得知会有多少冲突   
多槽位法在空间效率和时间效率之间的两准处境，我们在学习向量时也曾遇到过，同样可以用列表解决，每个桶单元挂一个链表
独立链 linked-list chaining / separate chaining 每个桶存放一个指针，冲突的词条，组织成列表   
优点√无需为每个桶预备多个槽位；任意多次的冲突都可解决；删除操作实现简单、统一   
缺点：指针需要额外空间；节点需要动态申请，这种动态申请（新增、销毁节点）相对于常规操作要高出两个数量级10²   
更重要的是，链表节点空间未必连续分布，系统缓存几乎失效，节点是沿着链表指针分布的，各节点的插入销毁次序可能是随机的，系统难以判断该缓存哪一部分数据来提高访问速度，当散列表规模非常大，需要IO操作辅助时，矛盾就会更加突出   
独立连法是封闭定制策略close addressing，地址不变，桶单元负责容纳所有冲突的词条   

开放定址 open addressing ~ closed hashing 为每个桶都事先约定若干备用桶，它们构成一个查找链probing sequence/chain   
所有的散列都在事先申请的连续封闭空间内完成，所有桶对所有词条开放，每—个词条都有可能存放进任何一个桶中，按照一定优先级试探各个桶单元，其中原本就该属于这个位置的词条优先级最高，依次不断向下试探，每个词条所对应的这样一个序列也称作试探序列   
查找:沿查找链，逐个转向下一桶单元，直到命中成功，或者抵达一个空桶（已遍历所有冲突的词条）失败   
线性试探 Linear probing：一旦冲突，则试探后一紧邻桶单元;直到命中成功，或抵达空桶失败   
优点︰无需附加的（指针、链表或溢出区等）空间；查找链具有局部性，可充分利用系统缓存，有效减少IO   
但是∶操作时间 > O(1)；冲突增多 ——- 以往的冲突，会导致后续更多的冲突 c1ustering   
懒惰删除:   
按照开放定址策略∶先后插入、相互冲突的一组词条，将存放于同一查找链中    
直接别除︰清除词条，回收空桶?问题∶查找链被切断，后续词条将丢失，明明存在，却仿问不到   
lazy removal:仅做删除标记，查找链不必续接，遇到删除标记当做有数据继续查找，而插入时当做空桶直接插入。针对开放定址策略，由于同一个桶单元会存在在多个查找链中，惰性删除可能是最优的方法      

排解冲突主要两类方法：封闭定址、开放定址   
开放定址(如线性试探)在空间使用上更为紧凑，在大规模数据使用时更占优势   
排解冲突：线性试探的问题在于试探距离太近，那就拉大间距   
平方试探 Quadratic probing ：以平方数为距离，确定下一试探桶单元（1² 2² 3² ...）   
1、4、9...间距由0、3、5逐渐增长   
查找链上,各桶间距线性递增,可以缓解数据聚集，一旦冲突,可聪明地跳离是非之地，但一定程度上会破坏数据的局部性，若涉及外存，在某些时候可能会导致IO访问的激增，系统缓存可能会失效，但一般问题不大，通常情况下缓存页面的规模都在若干个KB左右，假设1个KB，如果桶单元只记录引用，大致只需要4个字节，那每个缓存页面至少能容纳256个桶单元，也就是16²，也就是说发生一次IO兑换，至少需要冲突16次   
平方试探可能导致空间浪费，申请的地址中有空桶，但无法访问到   
根据数论的知识，M若为合数: n²%M 可能的取值必然少于 [M/2]种 (一个数的平方，相对于另一个数的同余类数量，由于n对M的同余最多M个，那n²的一定小于M/2)，此时 ，只要对应的桶均非空...（会发生例如IO兑换之类的情况）   
同样数论知识，M 若为素数: n² % M 可能的取值恰好会有 M/2（向上取整） 种，恰好是查找链的前 M/2 项，由于素数除了2都是奇数，上整，刚刚超过50%，50%是其中的最坏情况   
定理:若M是素数，且 装填因子λ ≤ 0.5，就不会出现多个试探位置指向同一个桶单元的情况（例如，i² 和 j² 相对于 M 同余，i² % M = j² % M）  
证明：（查找链前缀,必足够长!）反证法，假设存在0 ≤ a < b< M/2，使得沿着查找链，第a项和第b项彼此冲突   
用数论的说法就是: a²和b²自然属于 M 的某一同余类,亦即
  a² ≡ b² (mod M)   
  b²-a² = (b+a)(b-a) ≡ 0 (mod M)，(b+a) 和 (b-a) 可以整除 M (假设 b ＞ a，b-a > 0，则 b+a > 0，由于M是乘积，所以b+a < M)    
然而: 0 < b-a < b+a < M，(b+a) 和 (b-a) 一定小于 M，这与M为素数矛盾(b+a至少是2)   

想要进一步提高装填因子，双向平方试探：自冲突位置起，依次向后试探   
[hash(key)+1²]%M，[hash(key)-1²]%M、[hash(key)+2²]%M、[hash(key)-2²]%M、[hash(key)+3²]%M、[hash(key)-3²]%M ...   
正向和逆向的子查找链,各包含[M/2]个互异的桶：-M/2，...，-2，-1，0，1，2，...，M/2   
但这两个子查找链，除了0可能包含公共的桶单元   
如果没有公共的是最好的，可以不浪费空间，比如11，前10次冲突刚好所有桶单元都用上了，比如第一次：1、第二次：11-1=10、4、11-4=7、9、11-9=2、16%11=5、-16%11=-5;11-5=6、25%11=3、-25%11=-3;11-3=8；7类似   
而如果有公共的桶单元，就说明两个查找链合起来并没有覆盖全部的地址空间，比如5，前4次：1、5-1=4、4、5-4=1，前4次冲突，双向试探的位置刚刚好重合了，还是只利用上了一半多，3个的空间，有两个浪费了；13类似，浪费了进一般，6个    
素数除了2，其余都可以分为两类，一类对4模余1，另一类模余3
表长取作素数 M= 4k + 3，必然可以保证查找链的前 M 项均互异   
双平方定理 Two-Square Theorem of Fermat: 任一素数 p 可表示为一对整数的平方和，当且仅当 p % 4 = 1    
只要注意到:    
(u² + v²)(s² + t²) = (us+vt)²+(ut-vs)²   
(2² + 3²)(5² + 8²) = (10+24)²+(16-15)²   








-----
[edit](https://github.com/saaavsaaa/saaavsaaa.github.io/edit/master/aaa/Structure_Abstract2.md)
